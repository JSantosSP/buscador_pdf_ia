[
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-0",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 0,
    "content": "id198165\n \n \nDEVELOPMENT OF A SYSTEM FOR PROPERTY\nDATA COLLECTION AND PROCESSING\nJOSÉ MIGUEL SANTOS PALOMERA\nThesis supervisor\nJOSEP Mª MIRABENT RODRIGUEZ (OWIUS)\nTutor: CARME QUER BOSOR (Department of Service and Information System Engineering)\nDegree\nBachelor's Degree in Informatics Engineering (Software Engineering)\nBachelor's thesis\nFacultat d'Informàtica de Barcelona (FIB)\nUniversitat Politècnica de Catalunya (UPC) - BarcelonaTech\n27/06/2025\n \n\nAbstract \nThis project involves the development of a digital tool aimed at commercial analysis in \nthe real estate sector. The proposed system enables the organization of property \ninformation and facilitates its analysis. To achieve this, data provided by two external \nservices are integrated, normalized, and stored in a database. Additionally, the system \nincludes a graphical interface for property management and more efficient analysis. \n \nResum \nAquest projecte consisteix en el desenvolupament d'una eina digital orientada a \nl'anàlisi comercial en el sector immobiliari. El sistema proposat permet organitzar la \ninformació de les propietats i facilitar-ne l'anàlisi. Per a això, s'integren dades \nproporcionades per dos serveis externs"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-1",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 1,
    "content": ", que es normalitzen i s'emmagatzemen en una \nbase de dades. A més, el sistema incorpora una interfície gràfica per a la gestió de les \npropietats i una anàlisi més eficient. \n \nResumen \nEste proyecto consiste en el desarrollo de una herramienta digital orientada al análisis \ncomercial en el sector inmobiliario. El sistema propuesto permite organizar la \ninformación de las propiedades y facilitar su análisis. Para ello, se integran datos \nproporcionados por dos servicios externos, los cuales se normalizan y almacenan en \nuna base de datos. Además, el sistema incorpora una interfaz gráfica para la gestión \nde propiedades y un análisis más eficiente. \n \n1 \n\nAcknowledgments \nFirst and foremost, I would like to express my sincere gratitude to the project \nsupervisor, Josep M.ª Mirabent, for giving me the opportunity to carry out this project \nand for trusting me to manage and develop it in its entirety. His support and extensive \nexperience have been essential throughout the entire process. \n \nSecondly, I am deeply thankful to the project tutor, Carme Quer, for her valuable \nassistance during the demanding documentation process. Her corrections, \nobservations, and different perspective"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-2",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 2,
    "content": "s have been key to achieving a clearer, more \ncomplete, more structured, and more comprehensible presentation of the work. \n \nLast but not least, I want to thank my family and colleagues, whose unconditional and \nconstant support has allowed me to reach this point, making this academic journey a \nmuch more manageable and enriching experience. \n \n \n2 \n\nIndex \n1. Introduction---------------------------------------------------------------------------------------------8\n \n1.1. Project context-----------------------------------------------------------------------------------8\n \n1.1.1. Context and Problem to be solved---------------------------------------------------8\n \n1.2. Goal-------------------------------------------------------------------------------------------------9\n \n1.3. Stakeholders------------------------------------------------------------------------------------10\n \n1.4. State of the Art---------------------------------------------------------------------------------11\n \n1.4.1. Existing solutions-----------------------------------------------------------------------11\n \n1.4.2. Justification------------------------------------------------------------------------------11"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-3",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 3,
    "content": "1.5. Risks-----------------------------------------------------------------------------------------------11\n \n1.6. Methodology-----------------------------------------------------------------------------------12\n \n1.6.1. Monitoring tools and validation----------------------------------------------------12\n \n1.7. Organization of memory subtraction------------------------------------------------------14 \n2. Planning-------------------------------------------------------------------------------------------------16\n \n2.1. Description of tasks---------------------------------------------------------------------------16\n \n2.1.1. Project Management------------------------------------------------------------------16\n \n2.1.2. Development----------------------------------------------------------------------------17\n \n2.1.3. Documentation of the TFG-----------------------------------------------------------19\n \n2.2. Resources----------------------------------------------------------------------------------------20\n \n2.2.1. Human resources-----------------------------------------------------------------------20\n \n2.2.2. Material Resource--------------------------------------------------------"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-4",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 4,
    "content": "--------------20\n \n2.3. Estimates and the Gantt Diagram----------------------------------------------------------20\n \n3. Budget---------------------------------------------------------------------------------------------------23\n \n3.1. Identification and estimation of costs----------------------------------------------------23\n \n3.1.1. Staff costs--------------------------------------------------------------------------------23\n \n3.1.2. General costs and amortisation-----------------------------------------------------25\n \n3.1.3. Contingency------------------------------------------------------------------------------26\n \n3.1.4. Incidentals--------------------------------------------------------------------------------26\n \n3.1.5. Final budget------------------------------------------------------------------------------26\n \n4. Specification of requirements---------------------------------------------------------------------27\n \n4.1. Requirements collection process----------------------------------------------------------27\n \n4.2. Functional requirements---------------------------------------------------------------------27\n \n4.3. Non functional requirements--------------------------"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-5",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 5,
    "content": "-------------------------------------28\n \n4.4. Conceptual Data Model----------------------------------------------------------------------29\n \n4.5. User Stories Description---------------------------------------------------------------------32\n \n5. System architecture----------------------------------------------------------------------------------35\n \n3 \n\n5.1. Physical architecture--------------------------------------------------------------------------35\n \n5.2. Logical architecture---------------------------------------------------------------------------36\n \n5.2.1. VPS web server logical architecture-----------------------------------------------37 \n5.2.2. Client web logical architecture------------------------------------------------------38\n \n5.3. Examples of sequence diagrams-----------------------------------------------------------40\n \n5.4. Used patterns-----------------------------------------------------------------------------------41\n \n5.4.1. MVC (Model - View - Controller)---------------------------------------------------41\n \n5.4.2. Feature-Based Architecture----------------------------------------------------------42\n \n5.4.3. Smart/Dumb Component--------------------"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-6",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 6,
    "content": "----------------------------------------42\n \n5.5. Database: Logical Design---------------------------------------------------------------------44\n \n5.6. Database: Physical Design-------------------------------------------------------------------47\n \n5.7. Interface Design--------------------------------------------------------------------------------49\n \n5.7.1. Properties--------------------------------------------------------------------------------49\n \n5.7.2. Pipeline-----------------------------------------------------------------------------------50\n \n5.7.3. Pipeline Status--------------------------------------------------------------------------51\n \n5.7.4. Configuration----------------------------------------------------------------------------52\n \n6. Implementation---------------------------------------------------------------------------------------53 \n6.1. Technologies and languages   used--------------------------------------------------------53 \n6.1.1. Backend developed with Node.js and Express.js------------------------------53 \n6.1.2. NoSQL database using MongoDB-------------------------------------------------53 \n6.1.3. Frontend built with React.js----------------------"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-7",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 7,
    "content": "------------------------------------53 \n6.1.4. Additional frontend technologies---------------------------------------------------53 \n6.2. Development tools-----------------------------------------------------------------------------54 \n6.2.1. Visual Studio Code---------------------------------------------------------------------54 \n6.2.2. Postman----------------------------------------------------------------------------------54 \n6.2.3. Windows PowerShell------------------------------------------------------------------54 \n6.2.4. Google Chrome-------------------------------------------------------------------------54 \n6.3. Relevant aspects of the code implementation------------------------------------------55 \n6.3.1. Implementation of API Endpoints--------------------------------------------------55 \n6.3.2. Implementation of data processing------------------------------------------------56 \n6.3.3. Implementation of the duplicate detection process----------------------------63 \n7. Testing---------------------------------------------------------------------------------------------------70 \n7.1. Postman----------------------------------------------------------------------------------"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-8",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 8,
    "content": "--------70 \n7.2. Google Chrome--------------------------------------------------------------------------------71 \n7.3. Tests performed by SetHome---------------------------------------------------------------72 \n8. Project execution------------------------------------------------------------------------------------73 \n8.1. Task Tracking with Asana--------------------------------------------------------------------73 \n8.2. Planning and Budget Changes-------------------------------------------------------------74 \n8.3. Level of satisfaction of requirements-----------------------------------------------------77 \n9. Legal aspects-------------------------------------------------------------------------------------------81\n \n9.1. Laws applicable to the project--------------------------------------------------------------81\n \n9.2. Licenses------------------------------------------------------------------------------------------82\n \n4 \n\n10. Sustainability-----------------------------------------------------------------------------------------83\n \n10.1. Economic---------------------------------------------------------------------------------------83\n \n10.2. Environmental--------------------"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-9",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 9,
    "content": "------------------------------------------------------------84\n \n10.3. Social--------------------------------------------------------------------------------------------85\n \n11. Conclusions and future work------------------------------------------------------------------86 \n11.1. Technical skills worked on------------------------------------------------------------------86 \n11.2. TFG’s connection to the degree and specialization---------------------------------87 \n11.3. Personal conclusions------------------------------------------------------------------------88 \n11.4. Future work------------------------------------------------------------------------------------89 \nReferences------------------------------------------------------------------------------------------------90 \nAppendixes-----------------------------------------------------------------------------------------------92 \n \n5 \n\nIndex of Figures \n \nFigure 1: Asana screenshot----------------------------------------------------------------------------12 \nFigure 2: Slack screenshot-----------------------------------------------------------------------------13 \nFigure 3: Bitbucket screenshot------------------------------------"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-10",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 10,
    "content": "-----------------------------------13 \nFigure 4: Gantt Diagram--------------------------------------------------------------------------------22 \nFigure 5: Conceptual Data Model--------------------------------------------------------------------31 \nFigure 6: Physical architecture------------------------------------------------------------------------36 \nFigure 7: Logical architecture-------------------------------------------------------------------------36 \nFigure 8: API Design with MVC Pattern------------------------------------------------------------38 \nFigure 9: Backoffice Design----------------------------------------------------------------------------39 \nFigure 10: Backoffice sequence diagram-----------------------------------------------------------40 \nFigure 11: Backend sequence diagram-------------------------------------------------------------41 \nFigure 12: Smart component example-------------------------------------------------------------43 \nFigure 13: Dumb component example-------------------------------------------------------------44 \nFigure 14: Properties Interface Design-------------------------------------------------------------50 \nFigure 15: Pipeline Interfac"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-11",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 11,
    "content": "e Design----------------------------------------------------------------51 \nFigure 16: Status Properties Interface Design----------------------------------------------------51 \nFigure 17: Configuration Interface Design---------------------------------------------------------52 \nFigure 18: Code used to download data-----------------------------------------------------------57 \nFigure 19: Code used to update or create a new property—--------------------------------58 \nFigure 20: Code used to get values associated with specific terms-------------------------59 \nFigure 21: The property image shown by the seller--------------------------------------------62 \nFigure 22: Google Maps image showing the resulting location-----------------------------62 \nFigure 23: Image showing that it is the same property----------------------------------------62 \nFigure 24: Code used to filter potential properties---------------------------------------------63 \nFigure 25: Code used to calculate score between properties--------------------------------64 \nFigure 26: Incoming property image----------------------------------------------------------------69 \nFigure 27: Existing property Image-------------------"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-12",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 12,
    "content": "-----------------------------------------------69 \nFigure 28: Testing Process Flow----------------------------------------------------------------------70 \nFigure 29: Using Postman example-----------------------------------------------------------------71 \nFigure 30: Using DevTools example-----------------------------------------------------------------72 \nFigure 31: Using Asana example---------------------------------------------------------------------73\n6 \n\nIndex of Tables \nTable 1: Tasks summary--------------------------------------------------------------------------------21 \nTable 2: Salary--------------------------------------------------------------------------------------------24 \nTable 3: Cost per task-----------------------------------------------------------------------------------24 \nTable 4: Resource----------------------------------------------------------------------------------------25 \nTable 5: Amortisation-----------------------------------------------------------------------------------25 \nTable 6: Contingency------------------------------------------------------------------------------------26 \nTable 7: Incident--------------------------------------------------"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-13",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 13,
    "content": "----------------------------------------26 \nTable 8: Budget-------------------------------------------------------------------------------------------26 \nTable 9: Properties endpoints------------------------------------------------------------------------55 \nTable 10: Pipelines endpoints------------------------------------------------------------------------56 \nTable 11: Notifications endpoints-------------------------------------------------------------------56 \nTable 12: Configuration endpoints------------------------------------------------------------------56 \nTable 13: Fields, Methods, and Normalization implemented in the Process------------65 \nTable 14: The Project final deviation---------------------------------------------------------------74 \nTable 15: The budget Project final deviation-----------------------------------------------------76 \nTable 16: Levels of achievement of functional requirements--------------------------------79 \nTable 17: Levels of achievement of non-functional requirements--------------------------80 \n \n \n \n7 \n\n1. Introduction \nThis project is a Bachelor's Final Degree Project from the Faculty of Informatics of \nBarcelona (FIB) at the Universitat Pol"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-14",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 14,
    "content": "itècnica de Catalunya (UPC), focused on the \nSoftware Engineering specialization. It is a project developed under modality B, as an \ninternship agreement between UPC and the company Owius Technologies S.L. \n \n1.1. Project context \nThis project is being carried out at Owius Technologies S.L., where I work. The \ncompany specializes in custom software development, third-party services integration, \nand the creation of API systems, DevOps services, and custom technology solutions to \nmeet each client's needs. Currently, I am working with a real estate client, which I will \ncall SetHome for confidentiality reasons, who is looking to have a better analysis of the \nreal estate market in the areas where their office staff works.   \n1.1.1. Context and Problem to be solved \nNowadays, the Internet has become the world's showcase. With just a few clicks, it is \npossible to buy or sell almost anything, from second-hand furniture to whole buildings. \nThis fact has driven the rise of platforms dedicated to the purchase and sale of real \nestate, such as Idealista, Fotocasa, Habitaclia, etc., which allow users to find properties \nthat would otherwise be very difficult to discover. From now on, ever"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-15",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 15,
    "content": "y time the word \n“platforms” is mentioned, it refers to these online platforms. \nAlthough these platforms have revolutionized the world of real estate sales and \npurchases, they are also creating significant challenges for the agencies working in this \nsector, including the agency SetHome. The main challenge they are facing is reaching \nfurther distances, since many potential clients may find  platforms like Idealista[1] more \nappealing than a local real estate agency from a town far from them. Despite SetHome \nmarketing efforts, they are losing many clients who choose to list their properties on \nsuch platforms. \nSetHome’s goal is to analyze the marketplace. As the agency is located in Alella, a \nmunicipality in the El Maresme region with only 10.200 inhabitants [2], is to analyze the \nmarket of real estate in the area of Masnou, Alella, or Tiana to Montgat, Premià, or \n8 \n\nVilassar, this analysis will allow SetHome to take strategic decisions on the areas \nwhere they seek for new clients.   \nThis project mainly consists of the development of a system automating the linkage \nbetween real estate data (from now on, referred to as properties) that come from \nselling advertisements an"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-16",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 16,
    "content": "d the cadastre [3] records, both provided by external \ncompanies. The cadastre is an official system that records the owners of land and of \nthe amount and value of the land they own. The linking of the data given by the \ndifferent sources and  its presentation to SetHome’s managers and staff will benefit \nSetHome from market analysis capabilities and increase the information about areas \nand zones of more interest and value.\n \n1.2. Goal \nThis section details the main goal and the subgoals that are sought to be achieved with \nthe implementation of the project.  \nThis project aims to develop an automated system that imports property data provided \nby a services company, links these properties with the cadastre information provided by \nanother external company, stores the cleaned data in the database and ultimately \npresents the final results to the managers through the SetHome's backoffice. \nThe subgoals of this project are listed below: \n● Integrate a third-party service that provides information about properties: \n○ Abstract the relevant information about these properties. \n● Compare and associate the data extracted by the system with the cadastre data \nprovided by an external com"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-17",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 17,
    "content": "pany: \n○ Assign to each property extracted a list of possible real addresses of the \nproperty, at best, only one address corresponds to each property. \n● Display the data collected at the client’s backoffice, and allow the SetHome \nusers the management of this data. SetHome’s managers must be able to: \n○ Verify that the final data collected correctly corresponds to the assigned \naddress. \n○ Edit the information of the collected properties. \n○ See the general information of properties. \n9 \n\n1.3. Stakeholders \nStakeholders in software development projects are individuals or groups with interest \nor influence over the project's success, including clients, users, developers, and \ninvestors. The stakeholders for this project are described below.  \nSoftware Developer:  \nResponsible for designing, developing, implementing, and documenting the system. In \nthis project I am the software developer and a stakeholder in the project because the \nfact that it ends successfully affects me in different aspects, on one side as a worker of \nthe company that is in charge of the project may affect on my professional reputation \nand potential promotions, on the other hand, since the project is my TFG i"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-18",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 18,
    "content": "ts result may \naffect to the completion of the TFG, and finally it may impact my final grade and \ngraduation prospects. \nTFG Director:  \nThe project director, Josep M. Mirabent, the CEO of Owius, is responsible for leading \nand overseeing the development of the TFG project to ensure that the established \nobjectives are met. He is a stakeholder of the project because he is responsible for \nmeeting the client's expectations and delivering results. So he has a vested interest in \ncompleting the project. \nTFG Tutor:  \nThe tutor of this final degree project, Carme Quer, is responsible for the academic \nguidance of the project and its proper completion. She is a stakeholder of the project \nbecause in her work as a teacher, the fact that a TFG ends successfully is also a \npositive thing due to her academic responsibility. \nSetHome Agents:  \nThe SetHome agents will be the primary users of the system, utilizing the platform to \nknow about the market of properties and sales. They are stakeholders of the project \nbecause their daily workflow and business growth will be helped with the platform’s \nfunctionality and reliability. \n10 \n\n1.4. State of the Art \n1.4.1. Existing solutions \nThe client"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-19",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 19,
    "content": "SetHome wants a solution that is not currently available on the market due to \nits highly specific needs. It requires software that integrates with its backoffice to \nvisualize the data, extracts information from properties in the areas of interest, and \ncompares the obtained data with its cadastre records. \n1.4.2. Justification \nSetHome has decided to contract a third-party service to provide property information. \nIn addition, SetHome has contracted another third-party service to make cadastre data \navailable, enabling comparison between both datasets in the backend. The results are \nstored in the database, which facilitates the creation of endpoints that make the \ninformation accessible to the backoffice, allowing SetHome staff to view and edit it. \n1.5. Risks \nThere is a possibility of risks affecting the project's functionality. Likewise, obstacles \nmay surface throughout its execution. \nInexperience with third-party services technologies  \n● Developers' lack of familiarity with third-party services may cause project \ndelays. \nChanges in the platform structure \n● If the third-party service changes the structure of the information, the integration \nwith this service would need"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-20",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 20,
    "content": "to be re-done. \nScarcity of property information  \n● If the data collected from service is insufficient to identify properties in the \ncadastre, the solution will need to be reconsidered. \nTask rectification \n● If tasks are not properly specified, they may need to be re-done in the future. \n11 \n\n1.6. Methodology \nFor this project, an adaptation of the Kanban[4] methodology has been chosen. This \nmethodology consists of creating a board with different tasks, each one represented as \na card. These cards move across predefined columns that reflect different stages of \ncompletion of the task represented by the card. By limiting the number of tasks in \nprogress at any given time, Kanban ensures a steady workflow and helps maintain \nfocus on delivering value. In this particular adaptation, the board is divided into four \ncolumns: Backend and Backoffice, which contain tasks related to the development of \nthe backend system and the internal management interface respectively, a Doing \ncolumn that holds tasks currently in progress, and a Done column that collects \ncompleted tasks. This structure improves workflow visualization and helps categorize \nwork more effectively based on the nature"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-21",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 21,
    "content": "and status of each task. \n \n \nFigure 1: Asana screenshot. Source: Own elaboration. \nThe reason for choosing this methodology is that it adapts very well to the need for \ngreat flexibility when changing objectives and allows for shorter task cycles. \nAdditionally, it does not require as rigid a structure as Scrum, making it a great fit for \nprojects handled by a single person, as it allows for a more fluid and self-managed \nworkflow. \n1.6.1. Monitoring tools and validation \nTo implement this methodology, the developer and the project director hold daily \nmeetings to monitor the workflow, as WIP (Work In Progress) is not explicitly defined. \nAdditionally, meetings will be held with the owner of the product to clarify doubts and \nobjectives. Various tools are used to validate that the objectives are met. \n● Slack[5] is used for communication between team members, specifically \nbetween the team lead and the developer. \n12 \n\n \nFigure 2: Slack screenshot. Source: Own elaboration. \n● Asana[6] is used as a Kanban board tool to manage the project visually and \nefficiently. It has a board where two columns (Backend and Backoffice) \nrepresent the To Do section. There is also a Doing column an"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-22",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 22,
    "content": "d a Done column \nto improve workflow transparency. Additionally, a Documentation column is \nadded, containing cards with relevant project information. This column is \ncreated for the programmer's convenience, allowing quick access to documents \nthroughout the project. \n● Bitbucket[7] is used for version control. The version control strategy is based \non a simple and effective workflow that allows you to maintain clean and \nwell-documented code. The project is organized into two main repositories: \nBackend and Backoffice. \nEach completed task is uploaded to the main branch with a commit. \nThe commit message contains a description, explaining what has been \nimplemented or fixed. If a task is long, it is divided into multiple partial commits, \nindicating in each message which part has been completed. \n \nFigure 3: Bitbucket screenshot. Source: Own elaboration. \n13 \n\n1.7. Organization of memory subtraction \nThe rest of the report is structured into several chapters that clearly and systematically \npresent the development of the project. Below is a description of each chapter's \ncontent: \n● Chapter 2 – Planning: This chapter outlines the project’s planned timeline, \nspecifying the tasks"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-23",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 23,
    "content": "carried out, their estimated and actual durations, as well as \nthe required human and material resources. It also includes Gantt charts and a \ndetailed description of each task. \n● Chapter 3 – Budget: This section analyzes the project costs, both in terms of \npersonnel and material resources. It also includes costs arising from \nunforeseen events, amortizations, and contingencies, along with an estimate of \nthe total cost. \n● Chapter 4 – Requirements Specification: Here, the system’s functional and \nnon-functional requirements are presented, along with the process followed to \ndefine them. User stories and the conceptual data model are also included. \n● Chapter 5 – System Architecture: This chapter describes the physical and \nlogical architecture of the system, including design patterns used, sequence \ndiagrams, the structure of the backend and backoffice, and database design. \n● Chapter 6 – Implementation: This section details the most relevant technical \naspects of the system's implementation, such as the technologies used, tools \napplied, and key code snippets. \n● Chapter 7 – Testing: The different types of tests carried out are explained, \nincluding how they were conducted and"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-24",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 24,
    "content": "the results obtained. \n● Chapter 8 – Project Execution: This chapter analyzes deviations from the \ninitial plan, the degree to which requirements were met. Each requirement’s \nfulfillment level is evaluated. \n● Chapter 9 – Legal Aspects: Applicable laws concerning data protection and \nsoftware licensing are discussed, as well as the legal implications of using \nthird-party services. \n14 \n\n● Chapter 10 – Sustainability: This section reflects on the project’s economic, \nenvironmental, and social impact, and how these aspects were considered \nthroughout development. \n● Chapter 11 – Conclusions and future work: General project conclusions, \nlessons learned, and potential areas for improvement or future development are \npresented. \n● References: All sources of information used during the project’s development \nare listed. \n● Appendix: Additional material is provided to enhance understanding of the \napplication. \n \n \n15 \n\n2.  Planning \nThe Project is developed under modality B (external company). It takes place between \nFebruary 20th and the end of June. It has an approximate duration of 540 hours \ndistributed over 90 working days. It is planned to dedicate around 6 hours per day, \ncombi"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-25",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 25,
    "content": "ning work at the company with additional tasks at home. In addition, every Friday, \na 30-minute time slot will be reserved for a meeting (MT), if needed, allowing \ndiscussions on whether ensuring objectives requires managing changes, re-planning, \nor re-estimating tasks, as well as other possible topics. \nThis schedule is based on the academic workload of the Final Degree Project, which \nconsists of 18 credits, equivalent to a total of 540 hours of dedication (30 hours per \ncredit). \nThe initial planning presented in this section serves as a general guide for the expected \nworkload and task distribution. However, it is important to note that the actual execution \nof the project may differ from this initial estimation. A detailed breakdown of the real \nexecution, including the total hours invested per task and the tasks actually completed, \nwill be documented in the final chapter of the report, titled Project Execution. \n2.1. Description of tasks \n2.1.1. Project Management \nContext and scope of the project \n● PM1 - Define context and scope \nThe documentation defining the project's context and problem is written, the scope is \ndetermined, and the methodology to be used is decided. Th"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-26",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 26,
    "content": "is task takes 24 hours to \ncomplete. Dependence: none. \nTime planning \n● PM2 - Define time planning \nThe tasks required to carry out the project are planned, estimating the necessary time \nfor each one. A Gantt chart is created to visually present the development plan. This \ntask takes 22 hours to complete. Dependence: PM1. \n \n16 \n\nBudget and sustainability \n● PM3 - Make budget and sustainability report \nThe costs of each phase are identified and determined. Mechanisms for controlling \nbudget deviations are described. Additionally, a sustainability report is written. This task \ntakes 18 hours to complete. Dependence: PM2. \nFinal document \n● PM4 - Prepare final document \nThe contents of all previously created documents will be integrated, correcting issues \nor redefining sections to ensure greater clarity. This task takes 26 hours to complete. \nDependence: PM3. \n2.1.2. Development \nFor all programming tasks, it is important to keep in mind that they include a testing \nperiod, even if it is not explicitly specified in the tasks. Because independent testing \ntasks are not considered during the process, testing must be carried out while new \nfeatures are being developed.  \nInception \n●"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-27",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 27,
    "content": "I1 - Requirement specification \nThe necessary requirements that the project must meet are defined in detail by holding \nvarious meetings or staying in contact via email with the client SetHome to better \nunderstand their needs. This task takes 15 hours to complete. Dependency: PM4. \n● I2 - Database Design \nThe existing database is analyzed to review the current data, and decisions are made \non which tables to add to manage the new information that will be stored. This task \ntakes 8 hours to complete. Dependency: I1. \n● I3 - Setup and Learning the Service Functionality \nThe contracted service is configured to allow access via its API, and its functionality is \nstudied. Additionally, the feasibility of continuing with this service for system integration \nis evaluated. This task takes 15 hours to complete. Dependency: I2. \nData collection \n● D1 - Selection of locations \n17 \n\nThe necessary logic is added to determine which locations the client is interested in \ndownloading. Both the backoffice and backend must be modified to manage this new \ninformation. This task takes 6 hours to complete. Dependency: I4. \n● D2 - Requesting Data from the Service and Analysis \nDevelop a backend proces"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-28",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 28,
    "content": "s to initiate the download for the selected locations and \nretrieve the obtained data. Analyze the collected data and determine how to compare it \nwith cadastre data. This task takes 30 hours to complete. Dependency: D1. \n● D3 - Storing the Data \nAdapt the data model designed in task I2 for a property to the obtained data and add \nthe storage logic into the process created in task D2, without normalization. This task \ntakes 8 hours to complete. Dependency: I2, D2. \nData Processing \n● P1 - Data Normalization \nCreate a process to normalize the data obtained from service and store it in the \ndatabase. Modify the process created in task D3 to incorporate this normalization step, \nreplacing the direct data storage with the normalized version. This task takes 40 hours \nto complete. Dependency: D3. \nComparison with cadastre Data \n● C1 - Implement Logic \nCreate a process that selects the possible cadastre properties that resemble a given \nproperty. Retrieve the address of each of these properties and assign them to the \nproperty in question. Add this process to the normalization step performed in task P1. \nThis task takes 40 hours to complete. Dependency: P1. \nData Visualization \n● V1 - Im"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-29",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 29,
    "content": "plement Views to Manage Properties \nCreate the logic to manage CRUD operations for a property in the backend and \nbackoffice. This task takes 18 hours to complete. Dependency: P1. \n● V2 - Implement Functionality Related to Property Addresses \nCreate the logic to display the address on Google Maps and delete addresses from the \nbackoffice. This task takes 12 hours to complete. Dependency: C1. \n● V3 - Implement Modal to View cadastre Data \n18 \n\nCreate the logic to display cadastre data from the assigned address of each property in \nthe backoffice. This task takes 18 hours to complete. Dependency: C1. \n● V4 - Implement Component for Quick Property View \nCreate a sidebar to view more details of a property. This task takes 20 hours to \ncomplete. Dependency: P1. \n● V5 - Implement Property Filter \nCreate a filter by different categories in the backoffice. This task takes 10 hours to \ncomplete. Dependency: V1. \nManagement Features \n● F1 - Assign Users to Properties \nCreate all the logic needed to assign users to properties. Includes adding a filter by the \nassigned user in the backoffice. This task takes 10 hours to complete. Dependency: \nV1,V5. \n● F2 - Add Button to Download Excel \nCreate"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-30",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 30,
    "content": "the logic to download an Excel file for the selected properties. This task takes \n25 hours to complete. Dependency: V1. \n● F3 - Implementing functionality related to managing property states \nCreate the logic and UI to manage property states. This task takes 12 hours to \ncomplete. Dependency: V1. \n● F4 - Implementation of Notifications for the User \nDevelop the logic and user interface to manage notifications. This task is estimated to \ntake 12 hours to complete. Dependency: V1. \nAutomation \n● A1 - Automate the Process \nSearch for and implement a Node.js library to launch the automatic download process. \nThis task takes 20 hours to complete. Dependency: D2. \n● A2 - Update Downloading and Cadastre Data \nModify the logic for importing cadastre data so that the downloading process is \ntriggered once it is updated. This task takes 4 hours to complete. Dependency: C1. \n2.1.3. Documentation of the TFG \n● DT - Documentation and Tracking \n19 \n\nA report is created for the project that documents the entire development process. In \naddition, meetings are held with the supervisor to track progress and resolve any \nissues. In addition, the time spent preparing the oral presentation is also tak"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-31",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 31,
    "content": "en into \naccount. As this task is transversal and occurs throughout all stages of the project, it is \npossible to accumulate 120 hours. Dependency: None. \n2.2. Resources \n2.2.1. Human resources \n● T - Carme Quer Bosor  \nThe Final Degree Project Tutor's job is to guide the student throughout the \nspecification, documentation, and presentation tasks, ensuring that the project meets \nthe agreed-upon specifications set at the beginning. \n● D - Josep Mª Mirabent Rodriguez \nThe Project Director's job is to oversee the development of programming tasks, \nidentifying relevant tasks and assisting in decision-making regarding critical aspects of \nthe process. \n● A - Jose Miguel Santos Palomera \nThe sole developer of the project and Final Degree Project student is responsible for \nsuccessfully completing all assigned tasks and documenting the process. \n2.2.2. Material Resource \n● PC - Laptop \nComputer used by the developer for programming and documentation tasks. Its \nspecifications include an Intel i7 processor, 16GB of RAM, and Windows 11 Home as \nthe operating system. It has Visual Studio Code installed. This setup allows the \ndeveloper to host the project locally for testing purposes. \n2.3"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-32",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 32,
    "content": ". Estimates and the Gantt Diagram \nThe following table summarizes the tasks explained above, to have a clear \nvisualization of the dependencies between them and the estimated time that is \nexpected to be in each of them. Additionally, the table includes a column detailing the \nnecessary resources for each task, such as personnel or tools, which allows for a more \ncomprehensive understanding of the project's requirements.  \n20 \n\nThis information will also be useful in the following chapter, where both the time \nestimations and the required resources will be used to estimate the overall budget of \nthe project. \nTable 1: Tasks summary. \n21 \nCode Title Time(h) Dependence Resource \nPM1 Define context and scope 24 - PM \nPM2 Define time planning 22 PM1 PM \nPM3 Make budget and sustainability report 18 PM2 PM \nPM4 Prepare final document 26 PM3 PM \nI1 Requirement specification 15 PM4 PM \nI2 Database Design 8 I1 PM \nI3 \nSetup and Learning the Service \nFunctionality \n15 I3 \nDB, \nService, Bitbucket \nD1 Selection of locations 6 I4 \nDB, FD, QA, \nBitbucket \nD2 \nRequesting Data from the Service and \nAnalysis \n30 D1 \nPM,DB, \nService, Bitbucket \nD3 Storing the Data 8 I2, D2 DB, Bitbucket \nP1 Data Nor"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-33",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 33,
    "content": "malization 40 D3 DB, Bitbucket \nC1 Implement Logic 40 P1 \nDB, \nService, Bitbucket \nV1 Implement Views to Manage Properties 18 C1 \nDB, FD, QA, \nBitbucket \nV2 \nImplement Functionality Related to \nProperty Addresses \n12 C1 \nDB, FD, QA, \nBitbucket \nV3 Implement Modal to View cadastre Data 18 P1 \nDB, FD, QA, \nBitbucket \nV4 \nImplement Component for Quick \nProperty View \n20 P1 \nFD, QA, \nBitbucket \nV5 Implement Property Filter 10 V1 \nFD, QA, \nBitbucket \nF1 Assign Users to Properties 10 V1, V5 \nDB, FD, QA, \nBitbucket \nF2 Add Button to Download Excel 25 V1 \nDB, FD, QA, \nBitbucket \nF3 \nImplementing functionality related to \nmanaging property states \n12 V1 \nDB, FD, QA, \nBitbucket \nF4 \nImplementation of Notifications for the \nUser \n12 V1 \nDB, FD, QA, \nBitbucket \nA1 Automate the Process 20 D2 \nDB, \nBitbucket \nA2 Update Downloading and Cadastre Data 4 C1 \nDB, FD, QA, \nBitbucket \nDT Documentation and Tracking 120 - PM, DB, FD, QA \nMT Meeting 7 - PM, DB, FD, QA \n Total hours 540   \n\nBelow is the Gantt chart, a project management tool that provides a graphical \nrepresentation of the project’s task schedule. It is displayed as a table with horizontal \nbars, where each bar indicates the duration of a"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-34",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 34,
    "content": "project task.  \nThis type of chart helps identify task dependencies and track the project's progress, \nsupporting a clear and organized view of the work required to complete the project. \n \n \n \n \n \n \n \n \n \n \n \n \nFigure 4: Gantt Diagram. Source: Own elaboration. \n \n22 \n\n3. Budget  \nThe budget presented in this chapter is an initial estimate based on expected \nresources, working hours, and possible unexpected expenses. It includes staff costs, \ngeneral expenses, amortisation, contingency, and incidentals. However, the final cost, \nreflecting the actual hours invested in each task and the real resources used, will be \nincluded at the end of the project, in the Project Execution chapter. \n3.1. Identification and estimation of costs \nAfter conducting a thorough forecast of tasks and deadlines over time, it is now time to \ncalculate the financial costs of the project. \nIt is important to keep in mind that, in a project, costs arise directly, either through the \npurchase of necessary hardware or software for development or through salaries and \ntaxes that must be paid for employees carrying out each task. Additionally, there are \nindirect costs, such as office expenses or asset depreciati"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-35",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 35,
    "content": "on. \n3.1.1. Staff costs \nIn this project, the tasks are more focused on the backend, and the UX aspect for the \nclient is not a priority. Additionally, the database is already set up, so the only task is to \nintegrate a new collection with its respective relationships. \nFor this reason, only the following roles are needed: \n● A Project Manager, responsible for making key decisions and handling general \nproject documentation. \n● A Backend Developer, in charge of integrating the new collection and carrying \nout all backend-related tasks. \n● A Frontend Developer, who will perform the necessary tasks to integrate the \nnew functionalities into the existing back office. \n● A QA Tester, who will test the features as the frontend completes tasks, \nensuring they are finished correctly or providing feedback to developers to \ncorrect any potential issues. \nTo estimate the cost of each worker, the average hourly salary in Spain has been \nresearched on Talent.com [8], and the results are as follows: \n23 \n\nRole Cost/hour Cost/hour + SS People \nProject Manager 17.95 23.34 1 \nBackend Developer 22.38 29.09 1 \nFrontend Developer 20 26.00 1 \nQA Tester 14.62 19.01 1 \nA table showing the gross salary,"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-36",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 36,
    "content": "then applying the 30% Social Security contribution, and finally the \nnumber of workers in that role. \nTable 2: Salary \nNow that the estimated salary for each role is determined, it is necessary to calculate \nhow many hours each person will work per task. This will provide an estimate of the \ntotal project cost in relation to employee salaries. \nDescription Hour PM BD FD QA \nCost (€) Total (€) \nPM1 - Define context and scope 24 24.00    560.16 \n2,100.60 \nPM2 - Define time planning 22 22.00    513.48 \nPM3 - Make budget and sustainability \nreport 18 18.00    420.12 \nPM4 - Prepare final document 26 26.00    606.84 \nI1 - Requirement specification 15 15.00    350.1 \n973.17 \nI2 - Database design 8 8.00    186.72 \nI3 - Setup and learning service \nfunctionality 15  15.00   436.35 \nD1 - Selection of locations 6  3.00 2.00 1.00 158.28 \n1,234.95 \nD2 - Requesting Data from the Service \nand Analysis 30 5.00 25.00   843.95 \nD3 - Storing the Data 8  8.00   232.72 \nP1 - Data normalization 40  40.00   1163.6 1,163.60 \nC1 - Implement logic 40  40.00   1163.6 1,163.60 \nV1 - Implement views to manage \nproperties \n18  2.00 14.00 2.00 460.2 \n1,966.56 \nV2 - Implement Functionality Related to \nProperty Add"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-37",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 37,
    "content": "resses \n12  2.00 8.00 2.00 304.2 \nV3 - Implement Modal to View Cadastre \nData \n18  1.00 15.00 2.00 457.11 \nV4 - Implement Component for Quick \nProperty View \n20   18.00 2.00 506.02 \nV5 - Implement property filter 10   7.00 3.00 239.03 \nF1 - Assign users to properties 10  3.00 5.00 2.00 255.29 \n1,573.87 \nF2 - Add Button to Download Excel 25  20.00 3.00 2.00 697.82 \nF3 - Implementing functionality related \nto managing property states \n12  4.00 6.00 2.00 310.38 \n24 \n\nF4 - Implementation of Notifications for \nthe User 12  4.00 6.00 2.00 310.38 \nA1 - Automate the process 20  20.00   581.8 \n690.03 \nA2 - Update downloading and cadastre \ndata 4  2.50 1.00 0.50 108.23 \nDT - Documentation and tracking 120 42.00 32.00 23.00 23.00 2,946.39 2,946.39 \nMT - Meeting 7 7.00 7.00 7.00 7.00 682.08 682.08 \nTotal hours of the project 540 \n 14,494.85 Total human cost of the project  \n \nShow the number of hours for each role, the cost per task, and the group cost are displayed \nTable 3: Cost per task \n3.1.2. General costs and amortisation \nIn every project, general expenses related to the resources used to carry it out must \nalso be considered. In this case, office expenses, third-party service costs, an"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-38",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 38,
    "content": "d the \ndepreciation of the laptops used by each worker should be taken into account. Visual \nStudio Code is free, as well as Bitbucket, since we have fewer than five employees: \n● Office: Since it is a coworking space, all expenses such as internet, electricity, \nwater, and office supplies are included in the monthly rent. The reference \nlocation used is Cloudworks [9]. \n● Laptop: Since there are four employees, a laptop that meets the necessary \nspecifications for their tasks is purchased for each of them. The reference \nmodel used is the HP 15-fd0096ns [10]. \n \nResource Cost/mounth Units Total \nRent Office 300.00 4 4,800.00 \n \nShows monthly cost and total in four months \nTable 4: Resource \n \nTo calculate the amortisation of each laptop, it is necessary to know the cost, useful \nlife, working days in Catalonia [11] (excluding 22 vacation days), daily workload, and \nproject duration. \nResource Cost Units \nUseful life \n(years) \nworking \ndays \nper year \nhour/day Total Hour Total \nLabtop HP 699.00 4 4 228 6 441 225.34 \nShows total amortisation for all four laptops \nTable 5: Amortisation \n25 \n\n3.1.3. Contingency \n \nAll projects should include a margin of error in their budgets, as unfo"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-39",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 39,
    "content": "reseen events \noften lead to additional expenses. Typically, this margin is calculated between 10% and \n20% of the total budget.   \nIn this case, a 10% margin is chosen as it represents the minimum value, ensuring the \nlowest possible budget for the client. \nHuman Resource Percentage Contingency \n14,494.85 5,025.34 10 1,952.02 \nShows total contingency cost \nTable 6: Contingency \n3.1.4. Incidentals \nIn addition to having a margin for unforeseen events, it is also important to assess how \nmuch the budget would increase if any of the risks outlined in section 4 of this \ndocument were to occur.   \nTo account for these risks in the budget, a percentage is assigned based on the \nlikelihood of each scenario happening, which is then multiplied by the estimated cost of \nthat specific case. \nIncident Risk(%) Hour Cost/hour \nTotal(€) \nR1 66 7 25 114.114 \nR2 11 21 25 57.057 \nR3 33 14 25 114.114 \nTotal  285.285 \nShows partial and total incident cost \nTable 7: Incident \n3.1.5. Final budget \nFinally, to calculate the total value of the budget, you simply have to add the total of the \npoints mentioned above: \nHuman Resource Contingency Incidentals Total \n14,494.85 5,025.34 1,952.02 285.29 21,757.4"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-40",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 40,
    "content": "9 \nShows total budget \nTable 8: Budget \n26 \n\n4. Specification of requirements \n4.1. Requirements collection process \nTo define the scope and functionalities the application had to include, a process of \nrequirements definition was carried out in collaboration with SetHome. Although the \noverall goal of the project was clear from the beginning, to manage and analyze \nproperty information using both internal and cadastral data, the specific functionalities \nwere refined through several meetings with the company's representatives. \nThese meetings were held exclusively with the Product Owner, who acted as the main \npoint of contact. All communication took place remotely via video calls, which allowed \nfor agile and efficient decision-making despite not being on-site. \nThe functional requirements came from the operational needs SetHome found in their \ndaily work, like detecting duplicates, tracking sales, or validating data with the cadastre. \nAn example was defining how to compare properties in the system with those in the \ncadastre. At first, attributes like title, location, year built, and area were considered. But \nat the client’s request, a new rule was set: the location must match"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-41",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 41,
    "content": ", and at least two of \nthese must also match: year built, area, or parcel number. This helped adjust the \nsystem to the client’s real validation needs. \nRegarding the non-functional requirements, they were established considering the \ncompany’s operating hours and the need for data to be available during the working \nday (from 9 a.m. to 8 p.m.). For this reason, it was decided to schedule the automatic \ndata update process at 10 p.m., making sure that the data is loaded and ready by the \nnext morning. \n4.2. Functional requirements \nA functional requirement [12] is a statement of what a product (system, subsystem, \ndevice, or software program) must do. Next, the functional requirements for the product \nthat this project develops are presented. \n \n● FR1 - The downloading process of information that the external services \nprovide must be executed automatically at configurable intervals set by the \nsystem administrator. \n27 \n\n● FR2 - The application must allow comparing properties with cadastral data, \nrequiring a mandatory match on the locality and, in addition, a match on at least \ntwo of the following attributes: construction year, surface area, or parcel \nnumber. \n● FR3 - When cada"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-42",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 42,
    "content": "stral data is updated, the system must automatically compare \nthe new information with the existing records and update them accordingly. \n● FR4 - The interface must allow the user to define an error margin for data \ncomparison between loading and cadastral records. \n● FR5 - The interface must include a section where the user can view and correct \ndetected data errors. \n● FR6 - The user must be able to validate and manually approve changes before \nupdating the database. \n● FR7 - The system must allow the reversal of changes in case a manual \ncorrection introduces errors. \n● FR8 - The interface must display a table with key property data, including \nreference, name, property type, location, price, surface area, address, \nadvertiser, and creation date. \n● FR9 - The interface with property data in a table must enable the display of \nassociated images within the table. \n● FR10 - The interface must include action buttons (for example: editing, \ndeleting). \n● FR11 - The interface must include an advanced filtering system, allowing users \nto search for properties by reference, title, price, surface area, property type, \nyear of construction, status, location, advertiser type, and assigned"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-43",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 43,
    "content": "user. \n● FR12 - Filters must be applicable in combination and should include sorting \noptions (ascending/descending) for different attributes. \n● FR13 - The system must allow selecting all properties that match the applied \nfilters. \n \n4.3. Non functional requirements  \nA non-functional requirement [12] is a statement of what a product is or how it will be \nconstructed, or a constraint on how the product will be designed or will behave. Next, \nthe non functional requirements for the product that this project develops are \npresented. \n \n28 \n\nInteraction Capability \n● NFR1 - The user must be able to access the information with the fewest clicks \n● NFR2 - Data must be accessible during business hours (9am - 8pm)  \nPerformance Efficiency \n● NFR3 - It must be possible to launch the downloading process every 24 hours \nMaintainability \n● NFR4 - It must be able to adapt to changes in the distribution of information \nreturned \n4.4. Conceptual Data Model \nIn a conceptual data model each class represents a set of objects that share common \nattributes and about which it is necessary to store information. The model also includes \nassociations existent among objects and the possible multiplicity"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-44",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 44,
    "content": "of these associations.  \n \nFigure 5 presents the class diagram in language UML with classes, attributes and \nassociations of the system developed in this project. In the diagram it is possible to \ndistinguish the classes added for the system developed and classes already existing \nbefore this project due to other software applications of SetHome. Specifically, the \nclasses shown in blue correspond to those that were already part of the system. The \nattributes included in the diagram are strictly those necessary to meet the established \nrequirements, and each attribute is associated with its corresponding data type. \n \nThe diagram focuses on a main class called Property, which forms the core of the \nsystem and contains all relevant information about a property. Additionally, there are \nother important classes, such as: \n \n● Pipeline: defines the possible states or stages a property can have within the \nprocess. \n● PossibleDuplicados: records possible duplicate properties to facilitate their \nmanagement. \n● Credentials: stores the credentials needed to access the external service \nprovided by SetHome. \n● SimilarityMatrix: stores similarity relationships between properties, showing"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-45",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 45,
    "content": "how closely related they are to each other. \n29 \n\n● Configuracion: contains the values and error margins used to calculate the \nsimilarity matrix or to determine if a cadastral property matches one from the \nProperty class. \n● PossibleCadastralProperty: records the relationship between a cadastral \nproperty and one in the system, identifying possible matches to facilitate \nvalidation and linking of data between both sources. \n● Price: maintains the price history associated with each property to perform \ntracking and trend analysis. \n● Address and ValidAddress: contain lists of addresses related to possible \ncadastral properties. For each PossibleCadastralProperty there is an Address, \nwhile ValidAddress are those addresses the administrator has verified and \nconfirmed as correct. \n \nAlthough the UML diagram provides a clear overall view of the system's structure and \nthe relationships between its entities, it can’t graphically represent all the specific \nconstraints and conditions that must satisfy the data of the domain. Therefore, the \nfollowing textual constraints are included, as they could not be expressed graphically: \nTextual Constraints \n● Each Address must be associated wi"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-46",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 46,
    "content": "th a unique PossibleCadastralProperty. \n● The price must be a positive value greater than zero. \n● The area must be a positive value. \n● The construction year must not be greater than the current year. \n● For each Address, there must be a corresponding value in \nPossibleCadastralProperty. \n● ValidAddress must be linked to the same property as the Address. \n● The Pipeline class must define a finite and ordered set of states. \n● A property can only be in one active state of the Pipeline at a given time. \n● The error margins defined in Configuration must be greater than 0. \n● The error margins defined in Configuration must be less than 100. \n \n30 \n\n \nFigure 5: Conceptual Data Model. Source: Own elaboration. \n31 \n\n4.5. User Stories Description  \nThe following section presents the user stories that describe the functional \nrequirements of the system. These stories are organized in a table format, where each \none includes its identifier code, title, a brief description, and the acceptance criteria that \ndefine its correct implementation. \n \n \nVPL View properties list \nAs a user, I want to be able to see all the downloading properties so that I can check \nthe relevant information for each"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-47",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 47,
    "content": "one. \n● A list of all properties is displayed. \n● The relevant information for each property is shown (Duplicates, Assigned \nUser, Reference, Name, Gallery, Property Type, Town, Price, Surface Area, \nAddresses, Advertiser, Created Date). \n \nASFP Add search/filter properties \nAs a user, I want to be able to search and filter properties so that I can find the ones \nI'm interested in. \n● The available filters are displayed. \n● The properties are filtered based on the applied filters. \n \n \nMIAP More information about a property \nAs a user, I want to be able to see more information about a property so that I can \nopen a window with more information \n● An option is displayed for each property to view more information. \n● A window with more information about the selected property is shown. \n \nOAP Original advertisement of the property \nAs a user, I want to be able to see original advertisement of a property so that I can \n32 \nSP Select a property \nAs a user, I want to be able to select a few properties so that I can work with that \nproperties group \n● The option to select a property is displayed. \n● The selected properties are assigned to the desired user. \n\nverify the information \n● An"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-48",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 48,
    "content": "option is displayed for each property to view the original ad. \n● A window with Original advertisement of the property is shown \n \n \n \n \n \nDESPL Download an excel with selected properties list \nAs a user, I want to be able to download an Excel with all the properties or a curated \nlist so that I can see an Excel with all the attributes of each property \n33 \nANP Add new property \nAs a user, I want to be able to create a new property so that I can give value to all of \nits attributes \n● The option to create a new property is displayed. \n● A form with all the property attributes is opened. \n● The property is created successfully. \nEP Edit property \nAs a user, I want to be able to edit a property so that I can see all attributes about \nthat and modify them. \n● All property attributes are displayed. \n● All property attributes can be edited. \n● The changes are saved correctly. \nDP Delete property \nAs a user, I want to be able to edit a property so that I can eliminate all information \nabout that \n● All information about the property is deleted. \n● Any relationships the property has are removed. \n● The images of the property are deleted. \nDEP Disable/enable a property \nAs an administrator"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-49",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 49,
    "content": ", I want to be able to disable or enable a property so that user \ncan’t see the property \n● Disabled properties are shown in red. \n● Disabled properties are displayed only if the filter is applied. \n\n● The option to download the Excel file is displayed. \n● An Excel file is downloaded with all the attributes of each selected property. If \nnone are selected, all properties are included. \n \nCPDD Create a pipeline drag and drop \nAs an administrator, I want to be able to change property state with a drag and drop \nso that I can see easily the property state \n● A screen is displayed with the list of properties in card format. \n● Cards can be moved from one status to another by dragging and dropping. \n● The property status is updated correctly. \n \nEPP Edit a pipeline \nAs an administrator, I want to be able to change the name, order and color of a \npipeline so that I can change that at any time \n● A screen is shown with the pipelines list sorted, each one with the value of \ntheir attributes. \n● Changes are correctly stored \n \nECAMP Edit configuration about matching process \nAs an administrator, I want to be able to change the configuration of the matching \nprocess so that I can adjust its"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-50",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 50,
    "content": "precision. \n● All the attributes used for matching and their current weights are displayed. \n● Changes are saved correctly. \n \nANWPAU Assign notification when a property is assigned to a user \nAs a user, I want to receive a notification when a property is assigned to me so that I \nam aware of the new assignment. \n● A notification is triggered when a property is assigned. \n● The user receives the notification in the system. \n● The notification is marked as unread until the user sees it. \n \n34 \n\n5. System architecture \nThis chapter provides a schematic overview of the system’s architecture, starting with \nthe physical architecture followed by the logical one. It will also include examples of \nsequence diagrams, discuss the design patterns used, and conclude with the database \ndesign. \n5.1. Physical architecture   \nThe physical architecture (see Figure 6) of the SetHome system is deployed on a \nVirtual Private Server (VPS) [13], which is a virtualized server that mimics a dedicated \nserver within a shared hosting environment and server provided by OVHcloud[14], and \nused through a browser from any physical device such as mobile, tablet or computer.  \n \nThe server has all the necessary"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-51",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 51,
    "content": "services installed and configured to run the system: \nNginx, PM2, and MongoDB, in addition to the Backoffice and Backend code. \n \n● Nginx[15] acts as a reverse proxy, receiving requests from the Internet and \ninternally redirecting them to the appropriate services based on the access \nURL. \n \n● The Backoffice is a web application developed with React.js. As a Single Page \nApplication[16] (SPA), it is served as static content by Nginx. \n \n● The Backend is a RESTful API developed in Node.js, responsible for \nprocessing the system logic and exposing the different endpoints. Its execution \nis managed by PM2, which ensures the continuous availability of the application \nand allows for monitoring and automatic restart in case of failures. \n \n● MongoDB[17] is the NoSQL database used, responsible for persistently storing \nall the data handled by the system. \n \nNginx is responsible for correctly routing the requests that come from different \nInternet-connected devices (computers, mobile phones, tablets), to the corresponding \nservice within the VPS. \n \n35 \n\n \nFigure 6: Physical architecture. Source: Own elaboration. \n5.2. Logical architecture  \nLogical architecture refers to how the differ"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-52",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 52,
    "content": "ent components and modules of the \nsoftware are organized and interact to carry out the application's functions and \noperations. This architecture focuses on the system's structure and conceptual design, \nwithout taking into account implementation details or concerns related to hardware or \ninfrastructure. \n \nFigure 7: Logical architecture. Source: Own elaboration. \n \nNext, there is a subsection per each package in the logical architecture of Figure 6.  \n36 \n\n5.2.1. VPS web server logical architecture \nThis section describes the logical architecture of the backend in the VPS web server. \nAs shown in Figure 7, a modular pattern based on the MVC [18] \n(Model-View-Controller) model has been adopted, with a detailed description provided \nin Section 5.4. This architecture enables a clear separation of concerns: routes define \nthe entry points (view), controllers handle the business logic, and models manage \naccess to the MongoDB database. \nThe structure is organized into Routers, Middlewares, Controllers, and Models: \n● Routers: Their role is to organize and manage the routes of the REST API. \nEach router represents a group of endpoints related to a specific object in the \nsystem. In th"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-53",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 53,
    "content": "is project, there are only five objects that require their own router: \n○ Property \n○ Pipeline \n○ Comment \n○ Notification \n○ Configuration \n● Middlewares: These are functions that run between receiving an HTTP request \nand the final execution of the endpoint logic. In this project, a security \nmechanism has been implemented using middlewares placed between the \nrouter and the controller. Specifically, a function called verifyTokens is used to \ncheck the validity of the JWT token included in the request. This middleware \nacts as an authentication filter: if the request does not include a valid token, an \nHTTP 403 (Forbidden) error is returned, preventing unauthorized access. This \napproach promotes system modularity and follows the DRY [19] (Don't Repeat \nYourself) principle, as it allows the middleware to be reused across multiple \nroutes without duplicating code. \n● Controllers: They contain the main logic for each operation associated with a \nroute. Therefore, there is one controller for each router, acting as an \nintermediary between the HTTP request and the data access layer. \n● Models: They define the structure of the data stored in the MongoDB database. \nEach model represents"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-54",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 54,
    "content": "a MongoDB collection with its corresponding fields, \nvalidations, and types. \nThe general flow of request processing (illustrated in Figure 8) is as follows: \n1. The router receives the HTTP request and directs it to the appropriate route. \n37 \n\n2. Before reaching the controller, middlewares such as verifyTokens are executed \nto perform preliminary validations. \n3. If the verification is successful, the controller processes the logic for the \nrequested operation. \n4. Finally, the model accesses the database to read or modify data, and the \ncorresponding response is sent back to the client. \nThis design enhances maintainability, scalability, and code reusability throughout the \nentire application. \n \nFigure 8: API Design with MVC Pattern. Source: Own elaboration. \n5.2.2. Client web logical architecture \nThis section describes the logical architecture of the Client web. As shown in Figure 9, \nthe component in the client is the backoffice, and here its structure is presented. The \nsource code of backoffice has been organized within the src folder, following a modular \nand scalable architecture, where each folder represents a functional package of the \napplication. \n● api: This folder"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-55",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 55,
    "content": "contains the general configuration for communication with the \nbackend. Additionally, this folder is structured into subfolders, one for each \ndomain data model, which allows for a modular organization of the functions \nresponsible for interacting with the different server endpoints. \n● app: This folder represents the functional core of the backoffice. Inside, various \nfolders are organized in a modular way: \n○ components: contains reusable UI components such as forms, buttons, \ntables, and other generic visual elements used throughout the system. \n○ hooks: stores custom functions that encapsulate reusable logic, such as \nauthentication handling or managing shared state between components. \n38 \n\n○ modules: structures business logic and views by functionality. It contains \nsubfolders such as: \n■ Auth, dedicated to managing the authentication process, \nincluding actions like logging in, registering, or logging out. \n■ Errors, which handles the views associated with system errors, \nsuch as 404 error pages. \n■ ContentManager, the core of the backoffice. This folder includes \na subfolder for each domain entity managed through the admin \npanel. For example, the property entity has its o"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-56",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 56,
    "content": "wn folder, where \nthe necessary views are defined to display, edit, and manage \nthose properties. This pattern is repeated for each relevant entity, \nfacilitating scalability and logical organization of the content. \n○ pages: includes the main pages of the backoffice. For instance, it \ndefines the general structure of the dashboard, which serves as a visual \ncontainer for the other modules. \n● metronic[20]: This folder contains components and the base design for the \ncooperative dashboard. \n● constants: This folder contains global variables and constant values used \nrepeatedly throughout the application, such as texts, keys, or predefined \nconfigurations. \n● utils: This folder contains generic helper functions that support the application \nlogic and can be reused across various modules or components. \nFigure 9 presents the  class diagram showing the main folders of the backoffice and the \nmost relevant components they contain. \n \nFigure 9: Backoffice Design. Source: Own elaboration. \n39 \n\nA functional module-based architecture has been chosen, as this structure offers \nmultiple advantages: \n● Scalability: Each entity (such as Property, User, etc.) is encapsulated in its own \nmodule"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-57",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 57,
    "content": "under ContentManager, making it easier to add new features without \nbreaking other parts of the system. \n● Code reusability: Folders such as components, hooks, utils, and api contain \nreusable elements that can be used throughout the entire system. \n● Separation of concerns: Folders are organized by purpose (UI, business logic, \nAPI connection, authentication, etc.), which improves maintainability and \nreadability. \n \n5.3. Examples of sequence diagrams  \nThis section presents an example of a sequence diagram (see Figure 10 and Figure \n11) that illustrates how the different classes of the backoffice and the API communicate \nwhen an administrator user successfully creates a new pipeline object, without any \nvalidation or credential errors occurring. \nFigure 10: Backoffice sequence diagram. Source: Own elaboration. \n \nThe API object represents the backend system. It is explained in detail in the following \ndiagram. \n40 \n\nFigure 11: Backend sequence diagram. Source: Own elaboration. \n \n \n5.4. Used patterns \nThis section describes the patterns used in structuring the code of this project: \nModel-View-Controler pattern, Feature-Based architecture, Smart/Dumb Component. \n5.4.1. MVC (Mode"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-58",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 58,
    "content": "l - View - Controller) \nThis pattern is used in web applications due to its ability to clearly and efficiently \nseparate responsibilities.  \n \nIn this project, the MVC (Model-View-Controller) architectural pattern is applied to \nstructure the backend logic within the VPS web server. This pattern ensures a clean \nseparation of responsibilities, and in the context of this REST API, it is implemented as \nfollows: \n● Model: This layer is implemented through the files in the models folder of the \nproject. Each model corresponds to a MongoDB collection (such as Property, \nPipeline, Comment, etc.) and defines the data schema, types, and validation \nrules. These models are responsible for directly interacting with the MongoDB \ndatabase to perform operations like creation, retrieval, update, and deletion of \ndata. \n● View: In this REST API, the view is not a graphical interface but is represented \nby the routes defined in the routers folder. These routes receive client requests, \n41 \n\napply middleware if necessary, and redirect the request to the appropriate \ncontroller. They are responsible for defining which endpoints are available for \neach entity and with which HTTP methods (GET, POST,"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-59",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 59,
    "content": "PUT, DELETE). \n● Controller: The logic for the controller layer is located in the controllers folder. \nEach controller is associated with a specific entity and is responsible for \nhandling the business logic of each operation. Controllers receive the data from \nthe routers, process it, and use the corresponding model to access or modify \nthe database. At the end of the process, the controller generates an appropriate \nresponse (in JSON format) to be sent to the client. \n \n5.4.2. Feature-Based Architecture \nThis pattern organizes code based on specific system functionalities rather than \ngrouping it by file type (components, pages, services, etc.). \n \nIn this project, the structure is organized around functional modules. For instance,  \nwithin the app/modules/ folder, Auth/ groups code for the authentication of users, \nincluding login, registration, and token management functionalities and \nContentManager/Property/ groups code related to property management. Each module \ncontains its own pages, logic, and related components, which facilitates maintainability, \nscalability, and separation of concerns. \n \nAdditionally, reusable components and common utilities are placed in separate fo"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-60",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 60,
    "content": "lders \nsuch as components/, hooks/, or utils/, in accordance with reuse and decoupling \nprinciples. This modular architecture supports collaborative development and allows \nnew features to be added in an organized and efficient manner. \n \n5.4.3. Smart/Dumb Component \nThe Smart Component / Dumb Component[21] design pattern is used to improve \nscalability, code readability, and component reusability. \n \nIn this project this pattern has been followed in the backoffice of the Client web to \nmaintain a clear separation between business logic and visual interface logic.  \nOne example of Smart Components is the EditEstadoPipeline component (see Figure \n12) . These types of components are responsible for: \n● Managing local state with useState. \n42 \n\nJavaScript\n● Making API calls. \n● Handling side effects with useEffect. \n● Performing validations. \n● Managing navigation and events. \n● Passing data to child (Dumb) components. \nAs can be seen in the Javascript code of the figure, the component manages data \nloading from the backend. Additionally, EditEstadoPipeline handles the save and delete \nlogic, navigation, validations, and controls a confirmation dialog. \n \nuseEffect(() => { \n  if (!est"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-61",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 61,
    "content": "adoPipelineId) { \n    disableLoadingData(); \n    return; \n  } \n  getEstadoPipelineById(estadoPipelineId) \n    .then((res) => { \n      if (res.status === 200) { \n        setEstadoPipeline(res.data); \n        disableLoadingData(); \n      } \n    }) \n    .catch((error) => { \n      alertError({ \n        error: error, \n        customMessage: \"No se ha podido obtener la estadoPipeline.\", \n      }); \n      history.push(\"/estados-pipeline\"); \n    }); \n}, [estadoPipelineId, disableLoadingData, history]); \nFigure 12: Smart component example. Source: Own elaboration. \n \nOne example of Dumb Component is the ConfirmDialog component (see Figure 13) Its \nfunctionalities are: \n● Its function is purely visual. \n● It receives all information from the parent component via props (title, open, \nsetOpen, onConfirm). \n● It contains no business logic. \n● Its sole purpose is to display a reusable interface for confirming actions. \nThis component has no knowledge of the context in which it is used, nor does it \nperform any specific business actions. It only knows that it must execute onConfirm() \nwhen the user accepts, and close itself when the user cancels. \n43 \n\nJavaScript\n \nconst ConfirmDialog = (props) ="
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-62",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 62,
    "content": "> { \n  const { title, children, open, setOpen, onConfirm } = props; \n  return ( \n    <Dialog open={open} onClose={() => setOpen(false)}> \n      <DialogTitle>{title}</DialogTitle> \n      <DialogContent>{children}</DialogContent> \n      <DialogActions> \n        <Button \n          variant=\"outlined\" \n          color=\"primary\" \n          onClick={() => { \n            setOpen(false); \n            onConfirm(); \n          }} \n        > \n          Yes \n        </Button> \n        <Button \n          variant=\"outlined\" \n          color=\"secondary\" \n          onClick={() => setOpen(false)} \n        > \n          No \n        </Button> \n      </DialogActions> \n    </Dialog> \n  ); \n}; \nFigure 13: Dumb component example. Source: Own elaboration. \n \n5.5. Database: Logical Design \nThis project extends an existing database, with new specific collections that support the \ndeveloped functionalities. The database management system used is MongoDB. It is a \ndocument-based NoSQL database that allows for modeling complex, embedded, and \nflexible data structures without the need for rigid schemas or strict relationships like \nthose in a relational database. \n \nThe collections added to the existing company da"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-63",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 63,
    "content": "tabase are the following: \n \n \n44 \n\n● property \nThis collection stores information about properties and serves as the core of the \nsystem. Each document includes: \n○ title(String) \n○ description(String) \n○ type(String) \n○ phone(String) \n○ area(Integer) \n○ price(Array of Objects) \n■ value(Integer) \n■ date(Date) \n○ añoConstruccion (Integer) \n○ certificadoEnergetico (String) \n○ gallery(Array of String) \n○ nplanta (Integer) \n○ nbaños (Integer) \n○ nhabitaciones (Integer) \n○ origin(String) (URL of the information source) \n○ anunciante(String) \n○ moreInfo(String) \n○ seen(Boolean) \n○ active(Boolean) \n○ createdAt(Date) \n○ updatedAt(Date) \n○ addresses(Arrays of Strings) \n○ validAddresses (Arrays of Strings) \n○ localidad(ObjectId) reference to Localidad collection. \n○ assignedUser(ObjectId) reference to User collection. \n○ status(ObjectId)  reference to Pipeline collection. \n○ evolution(Array of objects) \n■ date(Date) \n■ status(ObjectId)  reference to Pipeline collection. \n○ potentialDuplicates(Array of ObjectId) reference to Property collection. \n○ possibleCadastralReferences(Array of ObjectId)  reference to \nCadastralProperty collection. \n○ comentarios(Array of objects) \n■ message(String)"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-64",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 64,
    "content": "45 \n\n■ user(ObjectId)  reference to User collection \n■ createdAt(Date). \n● configurations \nThis collection stores the weight values assigned to each property attribute in \norder to determine whether a property is a duplicate. It also contains the error \nmargins used for matching properties with the official cadastral database. Each \ndocument includes: \n○ weights(Object): \nAn object containing the weights for each attribute used in duplicate \ndetection calculations: \n■ title(Double) \n■ description(Double) \n■ moreInfo(Double) \n■ address(Double) \n■ price(Double) \n■ area(Double) \n■ nhabitaciones(Double)  \n■ nbaños(Double) \n■ nplanta(Double) \n■ añoConstruccion(Double) \n○ errorFactors(Object): \nAn object containing the error margin (in percentage) for each attribute \nused in cadastral property matching: \n■ areaError(Integer) \n■ parcelaError(Integer) \n■ areaErrorIfExact(Integer) \n■ añoConstruccionError(Integer) \n■ priceError(Integer) \n● similarityMatrix \nStores similarity matrices between properties to detect potential duplicates. \nEach document includes: \n○ date(Date)(The date the matrix was generated) \n○ matrix(Array of Objects) \n■ propertyId(ObjectId)(the base property) \n■ similarities"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-65",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 65,
    "content": "(Array of objects)(representing similar properties) \n➢ propertyId(ObjectId)(the comparable property) \n➢ score(Double)(the similarity score)  \n46 \n\n● pipeline \nRepresents the flow of statuses that a property goes through in the commercial \nprocess. Each document includes: \n○ name(String) \n○ color(String) \n○ order(Integer) \n○ items(Array of ObjectId) \n○ createdAt(Date) \n○ updatedAt(Date) \n \n● credentials \nAuxiliary collection that stores authentication tokens used to integrate the \nsystem with the external tool. Each document contains: \n○ access_token(String) \n○ refresh_token(String) \n○ token_type(String) \n○ expires_in(Integer) \n○ createdAt(Date) \n○ updatedAt(Date) \n \n● notification \nKeeps a record of all notifications delivered to users. Each document contains: \n○ seen(Boolean) \n○ active(Boolean) \n○ message(String) \n○ destinationUser(ObjectId) \n○ propertyId(ObjectId) \n○ createdAt(Date) \n○ updatedAt(Date) \n \n5.6. Database: Physical Design \nAt the physical level, a series of decisions have been made to maximize performance, \nensure proper scalability, and facilitate system maintenance. These decisions are \nsummarized in the following points: \n \n47 \n\nJavaScript\n● Traceability \nAll docu"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-66",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 66,
    "content": "ments include audit fields createdAt and updatedAt to preserve the \nhistory and evolution of the data. \n \n● Data Types \n○ Dates \nMongoDB's native Date type (represented as { \"$date\": \"...\" }) is used to \nallow sorting, filtering, or calculating time ranges. \n○ Identifiers \nAll document IDs (_id) and references (propertyId, localidad, \nassignedUser, etc.) use MongoDB’s standard ObjectId type. \n○ Numeric values \n■ area, nbaños, nhabitaciones, nplanta, and price.value use \ninteger, as decimal values are not meaningful for these fields. \nFor example: \n➢ area does not include decimals in the provided data. \n➢ price values are typically large, and decimals are not \nused. \n➢ The number of bathrooms, rooms, and floors are always \nwhole numbers. \n■ score in similarityMatrix allows a Double to represent the \nsimilarity between properties with decimal precision. \n○ Text strings  \nDescriptive fields like title, description, origin, anunciante, moreInfo, \namong others, use the string type to be able to have greater flexibility. \n \n● Defined Indexes \nTo improve performance for the most common queries, the following indexes \nhave been created: \n○ In the property collection: \npropertySchema.index("
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-67",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 67,
    "content": "{ createdAt: -1 }); \npropertySchema.index({ localidad: 1, area: 1, añoConstruccion: 1 }); \nThe first one allows for quick sorting of properties by creation date \n(useful for displaying recent listings). \n48 \n\nJavaScript\nThe second one facilitates searches based on geographic and physical \ncriteria, such as “properties in a specific locality with a certain size and \nconstruction year.” \n○ In the similarityMatrix collection: \nsimilarityMatrixSchema.index({ date: -1 }); \nsimilarityMatrixSchema.index({ \"matrix.propertyId\": 1 }); \nThe index on date optimizes the retrieval of the most recently generated \nmatrix. \nThe index on matrix.propertyId enables fast access to the similarities \nassociated with a specific property. \n \n5.7. Interface Design \nThis section explains the organization of the new views added to the backoffice.  \nThe base structure of the backoffice interface is a main dashboard that features a side \nmenu with different navigation options. Four new sections have been added to the \ndashboard: Properties, Pipeline, Pipeline States, and Configuration. Next there is a \ndescription of design layouts for each section, the screens they include, and how users \ncan navigate between"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-68",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 68,
    "content": "them. \n5.7.1. Properties \nThis part of the backoffice interface is designed to facilitate property management for \nthe user (see Figure 14). It consists of three screens, with the main one being \nPropertiesPage, which displays a filter and a table containing relevant information \nabout each property. From this screen, users can activate/deactivate or delete a \nproperty, access the original data source, and add or edit properties. To add or edit a \nproperty, users are redirected to the EditProperty screen. \nAdditionally, there is a side panel that opens with a summarized view of the property, \nallowing users to assign it to an agent, edit fields such as title, description, price, and \narea, or add comments. \n49 \n\nFigure 14: Properties Interface design. Source: Own elaboration. \n5.7.2. Pipeline \nThis part of the backoffice interface facilitates to the user the management of the status \nof properties  (see Figure 15). It displays a screen with a drag-and-drop interface, \nwhere each column represents a status previously defined by the administrator. \nProperties can be freely moved from one status to another. Additionally, it includes the \nsame filtering system as the PropertiesPage scr"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-69",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 69,
    "content": "een, allowing users to view only the \nproperties they are interested in. \n50 \n\nFigure 15: Pipeline Interface design. Source: Own elaboration. \n5.7.3. Pipeline Status \nThis part of the backoffice interface facilitates to the user the management of  the \ndifferent statuses that make up the pipeline  (see Figure 16). It includes a filter and a \ntable displaying the existing statuses, ordered from the first to the last. From this view, \nusers can delete a status, change its order, or navigate to the edit screen to add a new \none or update an existing status. \n \n \n \n \n \n \n \n \nFigure 16: Status Properties Interface design. Source: Own elaboration. \n51 \n\n \n5.7.4. Configuration \nThis part of the backoffice interface facilitates to the user the edition of the different \nvalues used in the duplicate detection process and in the cadastral property search  \n(see Figure 17). It consists of a screen with a form where users can adjust the weights \nand error margins for each attribute. \nFigure 17: Configuration Interface design. Source: Own elaboration. \n \n52 \n\n6. Implementation \n6.1. Technologies and languages   used \nThis project, composed of a backoffice and a backend, has been designed with a"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-70",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 70,
    "content": "focus \non adaptability and scalability over other aspects. For this reason, the following \ntechnologies were selected, as they support these objectives. \n6.1.1. Backend developed with Node.js and Express.js \nThe backend is developed using Node.js and Express.js, technologies that enable the \ncreation of a lightweight, efficient, and easily scalable architecture. This choice \nresponds to the need for a system that can adapt to potential changes in context and \ngrow according to SetHome's demands. Additionally, the backend is deployed on an \nOVHcloud VPS server, ensuring a flexible, controlled environment with dedicated \nresources, thus contributing to a robust infrastructure prepared for growth. \n6.1.2. NoSQL database using MongoDB \nFor data management, a NoSQL database using MongoDB was chosen, as its flexible \ndocument-based structure allows greater adaptability to changes in the data model, \nsomething especially useful during the early stages of the project's development and \nevolution. Additionally, MongoDB facilitates handling large volumes of data and offers \nhigh performance in read and write operations, which directly contributes to the \nsystem's scalability. This choice als"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-71",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 71,
    "content": "o enables a more natural integration with Node.js, \noptimizing both the development and maintenance of the backend. \n6.1.3. Frontend built with React.js \nReact.js was chosen for the development of the backoffice due to its ability to build \ndynamic, efficient, and easily maintainable user interfaces. React enables effective \nstate management and code modularization through reusable components, which \nimproves scalability as the project grows. In addition, its wide range of libraries and \ntools accelerates development. This choice contributes to a modern and adaptable \ninterface, aligning with the goals of flexibility and continuous system evolution. \n6.1.4. Additional frontend technologies \nIn addition to React.js, HTML and CSS were used in the development of the backoffice \nto structure and style the user interface. HTML made it possible to define the hierarchy \n53 \n\nand organization of the content, while CSS was used to apply visual styles, ensuring a \nclear and consistent presentation. These fundamental languages have played a key \nrole in complementing React’s logic and delivering an attractive and functional user \nexperience. \n6.2. Development tools \nThroughout the development"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-72",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 72,
    "content": "of the project, various tools were used to provide \nsolutions during different phases of the process, ranging from programming to \nproduction environment management. Below is a description of the main uses of each \nof them. \n6.2.1. Visual Studio Code  \nVisual Studio Code was the main development environment used throughout the \nproject. Its broad compatibility with JavaScript, along with seamless integration with \ntechnologies such as Node.js, MongoDB, and React, made it the ideal choice for both \nbackend and backoffice development. In addition, the wide range of available \nextensions, such as ESLint for code quality, Prettier for formatting, and Git integration, \nhelped maintain clean and consistent code throughout the entire project. \n6.2.2. Postman \nPostman was used as the main tool for testing and debugging the different endpoints \ninvolved in the system. Thanks to its intuitive interface, it facilitated the verification of \ncorrect functionality, response validation, and error analysis. \n6.2.3. Windows PowerShell \nPowerShell was used as the primary terminal for interacting with the production server. \nThrough this tool, remote connections via SSH were managed, allowing access"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-73",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 73,
    "content": "to \nperform deployment, monitoring, and system maintenance tasks. Additionally, \nPowerShell was used to launch local servers during development. Its integration with \nthe Windows environment enabled efficient management. \n6.2.4. Google Chrome \nGoogle Chrome has been the primary tool for browsing and testing the system \nthroughout the entire project development. Thanks to its powerful built-in developer \ntools (DevTools), it has allowed inspecting and debugging frontend code, analyzing \n54 \n\nperformance, reviewing the error console, and monitoring network requests. \nAdditionally, Chrome has facilitated checking the user interface across different \nresolutions and devices, ensuring an optimal and consistent experience for the end \nuser. \n6.3. Relevant aspects of the code implementation \n6.3.1. Implementation of API Endpoints \nOne of the most important aspects of this project is the communication between the \nbackoffice and the backend thanks to the REST API implemented in the backend that \nis accessible through endpoints. Next (Tables 9 to 12), the list of REST API endpoints \nis included. For each endpoint, it is detailed its purpose, URL, and HTTP method to use \nit.  \nProperties en"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-74",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 74,
    "content": "dpoints \nGET /api/property/count \nCount all properties \nPOST /api/property \nAdd property \nPUT /api/property/change-status/{id} \nChange status of property's active attribute by id \nPUT /api/property/{id} \nUpdate property \nGET /api/property/{id} \nGet property by id \nPOST /api/property/byIds \nGet properties by a ids list \nGET /api/property \nGet all properties with query. \nOptions: page, limit and refId \nGET /api/property/user/:userId \nGet all properties by userId with query. \nOptions: page and limit \nDELETE /api/property/{id} \nDelete property by id \nPOST /api/property/addresses \nUpdate Addresses from individual property \nTable 9: Properties endpoints \n \n \n55 \n\n \nPipelines Endpoints \nPOST /api/pipeline \nAdd pipeline \nPOST /api/pipeline/swap-orders \nSwap orders \nPUT /api/pipeline/{id} \nUpdate pipeline \nGET /api/pipeline/{id} \nGet pipeline by id \nGET /api/pipeline \nGet all pipelines \nDELETE /api/pipeline/{id} \nDelete pipeline by id \nTable 10: Pipelines endpoints \n \nNotifications Endpoints \nGET /api/notification/user/:id \nGet notification by User id \nPOST /api/notification \nAdd notification \nPUT /api/notification/change-status/{id} \nChange status of notification by id \nTable 11: Notificat"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-75",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 75,
    "content": "ions endpoints \nConfiguration endpoints \nGET api/configuration/{id} \nGet configuration by id \nPUT api/configuration/{id} \nUpdate configuration by id \nTable 12: Configuration endpoints \n \n6.3.2. Implementation of data processing \nIn the development of this project, the main functionality, which also provides the \nsystem’s core data, represents a critical component within the overall workflow. Its \ncorrect operation is essential, as any failure at this stage could compromise the \nintegrity of the property information. The primary goal of this functionality is to \nnormalize the data coming from the external service provided by SetHome. \n56 \n\nThe process is structured into three distinct phases: \n● First, the property data stored in SetHome’s service is downloaded.  \n● Next, this information is normalized, a process that includes linking it with data \nfrom the cadastre. \n● Finally, the system checks whether each property is already registered in the \ndatabase in order to update its values or, if not, to add it as a new entry. \nNext, the implementation of these phases is described. \nSince the data download is limited to a single request to the external service, the Axios \nrequest and th"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-76",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 76,
    "content": "e reception of the response can be seen in Figure 18, and the updating \nor insertion of properties can be seen in Figure 19, where the system checks whether \nthe property exists and then creates or updates it based on the result of that check, the \nexplanation will focus on the normalization stage, as it is the most complex and critical \ncomponent of the process. \n \nFigure 18: Code used to download data. Source: Own elaboration. \n57 \n\n \nFigure 19: Code used to update or create a new property. Source: Own elaboration. \n \nNormalization including linking it with data from the cadastre \nNormalization begins with identifying the most likely locality of a property, using both \nthe location field and the title. The terms present in these fields are compared against a \nlist of localities stored in the Localidades collection, selecting the one with the highest \nmatch. Then, the property type is determined by analyzing the title for representative \n58 \n\nkeywords such as \"apartment\", \"house\", \"penthouse\", etc. (Figure 1 in the Appendix \nshows the code used to link the Localidad with a property). \nOnce the locality and property type have been identified, the basic features are \nextracted from"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-77",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 77,
    "content": "the Características_básicas field, which is provided as a text string. This \nallows the system to obtain the number of rooms, bathrooms, and the floor on which \nthe property is located, as well as the year of construction, provided it is indicated in a \nvalid format. Additionally, surface-related metrics are extracted, such as built area, \nusable area, and plot size, by locating the values associated with specific terms like \n“construidos”, “útiles”, or “parcela” (see Figure 20). \n \nFigure 20: Code used to get values associated with specific terms. Source: Own elaboration. \n \nThe normalization of the property name is performed based on the title, removing \ngeneric terms in order to retain only the meaningful part of the name. With the \nextracted information, a search is conducted for similar properties in the cadastral \ndatabase, using locality, built area, usable area, and year of construction as \nparameters. The goal of this procedure is to identify potentially associated cadastral \nreferences and relevant addresses. (Figure 2 in the Appendix shows the code used to \nsearch for cadastral properties in the database). \nFinally, a structured object is built that integrates all the tr"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-78",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 78,
    "content": "ansformed information: title, \ndescription, address, physical characteristics, price, and estimated cadastral \nreferences. Additionally, an initial status is assigned within the commercial pipeline, \nalong with an evolution history that begins on the record’s creation date. The resulting \nproperty is marked as active, unviewed, and ready to be managed within the system. \nAfter that, the code is executed to update or add the normalized property (see Figure \n19). \n \n59 \n\nJSON\n \nReal Example \nBelow a simplified example of the phases implementation is described, based on real \ndata, that illustrates how the analysis process works within the system. First, the data \nreceived from the key variables is shown. Then, the processed data derived from them \nis presented. After that, the property is linked to the cadastre data, and finally, the \nresults are illustrated with images. \nIt focuses on three key variables: Título, Ubicación, and Características_básicas, as \nthey contain the most relevant information. It is important to note that all the variables \nreceived are text strings. In this example, their values are as follows: \n● Título: \"Casa o chalet independiente en venta en Can Teixidó -"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-79",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 79,
    "content": "Can Sors\" \n● Ubicación: \"Distrito Can Teixidó - Can Sors, Alella, Maresme, Barcelona\" \n● Características_básicas: \"Casa o chalet independiente 3 plantas 532 m² \nconstruidos 453 m² útiles 5 habitaciones 5 baños Parcela de 1.204 m² Terraza y \nbalcón Plaza de garaje incluida en el precio Segunda mano/buen estado \nArmarios empotrados Trastero Orientación sur, este Construido en 1997 \nCalefacción individual: Gas natural\" \nFrom this information, the goal is to automatically extract the following structured data: \n● localidad \n● nplantas \n● nhabitaciones \n● nbaños \n● añoConstrucción \n● parcela \n● construidos \n● utiles \nThe first step is data normalization. To achieve this, key expressions are applied \nthrough an extraction function (see Figure 20). This process allows the data to be \nidentified and structured as follows: \n\"construidos\": 532, \n\"utiles\": 453, \n\"parcela\": 1204, \n\"nhabitaciones\": 5, \n\"nbaños\": 5, \n60 \n\nJSON\nJSON\n\"nplanta\": 3, \n\"añoConstruccion\": 1997 \nNext, based on the Titulo and Ubicación, a match is searched for with the names of the \nlocalities stored in the database. This process is carried out through a specific function \n(see Figure 1 in the Appendix). In this example"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-80",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 80,
    "content": ", the locality is successfully identified as \nAlella. \nWith all this data already structured, the system proceeds to search for possible \nmatches with properties registered in the cadastralProperties collection. To do this, the \nfunction shown in Figure 2 in the Appendix is called, which performs progressive \nsearches in the database, starting with the strictest filter. If no results are found, \nrestrictions are gradually removed. \nIn this case, having all the key fields available, a single match was found, and the final \nresult is: \n\"possibleCadastralReferences\": [\"1521002DF4912S0001ZJ\"], \n\"addresses\": [ \n  \"Distrito Can Teixidó - Can Sors, Alella, Maresme, Barcelona\", \n  \"CL, LLAÜT, 3, 0, T, OD, OS, ALELLA, Barcelona, 8328\" \n], \n\"validAddresses\": [] \n \nAt this point, the system displays both the original address and the address obtained \nfrom the cadastre. The automatic process ends here, and now it is SetHome, through \nthe backoffice and the use of Google Maps, who must verify and validate the correct \naddress. After validation, the validAddresses field is updated as follows: \n \n\"addresses\": [\"Distrito Can Teixidó - Can Sors, Alella, Maresme, \nBarcelona\"\n], \n\"validAddresses\": [\""
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-81",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 81,
    "content": "CL, LLAÜT, 3, 0, T, OD, OS, ALELLA, Barcelona, \n8328\"\n] \n \n61 \n\nBelow, it can be seen how the images from the property's listing (see Figure 21) \ncorrespond to the Google Maps images (see Figures 22 and 23), which show the \nassigned address of the property. \n \nFigure 21: The property image shown by the seller. Source: Premium Houses [22]\n. \n \nFigure 22: Google Maps image showing the resulting location. Source: Own elaboration. \n \nFigure 23: Image showing that it is the same property. Source: Own elaboration. \n62 \n\n6.3.3. Implementation of the duplicate detection process \nThe process of detecting duplicate properties plays a key role within the properties \nmanagement system, as it enables the identification of repeated entries that, despite \nslight variations, represent the same property. This automated process optimizes \ncommercial analysis. To achieve this, several technical components interact, including: \ncustom configuration for each attribute, a similarity matrix stored alongside the score \nhistory, and an execution architecture based on threads (workers) that distribute the \nworkload in parallel. (Figure 3 in the Appendix shows the code used to create a \nWorkerPool) \nThe proc"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-82",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 82,
    "content": "ess begins with the retrieval of new or updated properties between the current \ndate and the last update of the similarityMatrix object, along with the configuration, \nwhich includes error margins that define when a property should be considered (see \nFigure 24) and weights that determine the relative importance of each field in the \nsimilarity calculation (e.g., title, description, price, area, among others). Based on this \nconfiguration, candidate properties that could be considered duplicates are filtered. \nThis filtering relies on criteria such as matching location and key numerical fields like \narea, yearBuilt, and price, taking into account the defined error margins. This \nsignificantly reduces the number of unnecessary comparisons. \n \nFigure 24: Code used to filter potential properties. Source: Own elaboration. \nFor each property, a task is generated and sent to a worker. Each worker receives a \ntask containing the property to be compared, a list of potentially similar properties, and \nthe weight configuration, and returns a set of valid similarity results. \n63 \n\nThe algorithm used to measure similarity (see Figure 25) combines different \napproaches depending on the type of"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-83",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 83,
    "content": "field. For text attributes such as title, description, \nmoreInfo, or addresses, a preprocessing step is applied that includes converting text to \nlowercase, removing special characters, and normalizing the format. Then, the \nstring-similarity library is used, which finds the degree of similarity between two strings, \nbased on Dice's Coefficient [23] distance to calculate a score between 0 and 1. \n \nFigure 25: Code used to calculate score between properties. Source: Own elaboration. \n64 \n\nOn the other hand, for numeric attributes such as price, area, or nplanta, the \ncomparison is based on the difference relative to a high reference value, transforming \nthe difference into a proportion that is normalized on a scale where 1 represents perfect \nequality and 0 represents complete dissimilarity. All these values are weighted \naccording to the predefined configuration to produce a final combined similarity score \n(see Table 13). \nShow all fields with their processes \nTable 13: Fields, Methods, and Normalization implemented in the Process \nOnce the result is obtained, if the score exceeds a value of 0.8, the property is \nconsidered sufficiently similar to be marked as a duplicate. These m"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-84",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 84,
    "content": "atches are stored \nin the similarityMatrix collection, and if the score is higher than 0.9, the match is also \nsaved directly in the property document under the potentialDuplicates field. After the \nprocess is completed, the date field of the similarityMatrix object is updated with the \ncurrent day's value. \nReal Example \nBelow is a simplified example, based on real data, that illustrates how the process of \ndetecting similar properties works within the system.  \nNext, the data used in the example is presented, followed by the obtained results, \nwhich are finally illustrated with images. \nIn this case, a new property is used as the starting point and compared with those \nalready stored in the database. Both the input data and the results automatically \ngenerated from them are shown. \n65 \nField Method Normalization / Range \ntitle string-similarity clean text \ndescription string-similarity clean text \nmoreInfo string-similarity clean text \naddresses string-similarity clean text \nprice absolute difference / 1x10\n6\n \n1 - diff / 1x10\n6\n \narea absolute difference / 500 1 - diff / 500 \nnhabitaciones absolute difference / 10 1 - diff / 10 \nnbaños absolute difference / 10 1 - diff / 10 \nnpl"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-85",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 85,
    "content": "anta absolute difference / 10 1 - diff / 10 \nañoConstruccion absolute difference / 100 1 - diff / 100 \n\nIt focuses on ten key variables: title, description, moreInfo, address, price, area, \nnumber of rooms, number of bathrooms, floor number, and year of construction, as \nthey are the main elements for the analysis. All these variables are compared using \ndifferent methods, depending on whether they are text or numerical values. \nIn this example, the values of the input property are as follows: \n● title: \"Casa o chalet independiente en venta en Can Teixido - Can Sors\" \n● description: \"Esta magnífica propiedad está situada en una de las mejores \nurbanizaciones del Maresme, Can Teixidó. A tan sólo 20 minutos de Barcelona, \n5 minutos andando a la playa y a 10 min. en coche al colegio Internacional \nHamelin. La casa está construida sobre una parcela totalmente plana de \n1.400m2 con jardín y piscina privados. Al entrar en la propiedad podemos \nobservar el excelente estado del jardín y los grandes árboles que tiene.  Con \nsólo entrar en la casa podemos disfrutar de un amplio recibidor a dos alturas \ncon una gran escalera con baranda de hierro forjado a medida. La planta \nprincipal tiene u"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-86",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 86,
    "content": "n agradable salón comedor con grandes ventanales que se \nabren al jardín y por los cuales entra muchísima luz, cuenta también con un \nsalón más pequeño con chimenea que resulta estupendo para las noches de \ninvierno desde el cual se ven agradables atardeceres con vistas al mar y al \nSkyline de Barcelona. La gran cocina office completamente equipada con mesa \npara 8 comensales y conectada al jardín mediante grandes puertas correderas \nque nos llevan al comedor exterior de verano y al porche. Además, esta planta \ndispone de una habitación doble con baño completo ideal para invitados. \nAnexo a la cocina dispone de una zona muy amplia de lavadero y habitación de \nservicio con baño incluido y un aseo de cortesía. En la primera planta \nencontramos la suite con grandes ventanales con vistas al mar y que cuenta \ncon un amplio vestidor y un baño completo más dos habitaciones dobles muy \ngrandes, todas ellas exteriores que comparten un gran baño. La propiedad \ndispone de un garaje para tres coches y en esa misma planta tenemos otra \nsala polivalente y un gran trastero.\" \n● moreInfo: \"Casa o chalet independiente  3 plantas  532 m² construidos, 453 m² \nútiles  5 habitaciones  5 baños  Parcela"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-87",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 87,
    "content": "de 1.204 m²  Terraza y balcón  Plaza de \ngaraje incluida en el precio  Segunda mano/buen estado  Armarios empotrados  \nTrastero  Orientación sur, este  Construido en 1997  Calefacción individual: Gas \nnatural\" \n● adress: \"CL, LLAÜT, 3, 0, T, OD, OS, ALELLA, Barcelona, 8328\" \n66 \n\n● price: 2.450.000 € \n● area: 532m² \n● nhabitaciones: 5 \n● nbaños: 5 \n● nplantas: 3 \n● añoConstrucción: 1997 \nThe property is compared with another property already existing in the database, \nwhose values   are: \n● title: \"Casa o chalet independiente en venta en Can Teixido - Can Sors\" \n● description: \"Situada en una de las mejores zonas del Maresme dentro de un \nresidencial privado a 400 metros de la playa, se encuentra esta magnífica \npropiedad de más de 500m2 construida por sus propietarios con mimo y \ndetalle. Asentada en una parcela de más de 1200m2 totalmente plana, la \npropiedad está distribuida en 2 plantas principales donde la entrada principal \nnos da acceso a un hall espectacular con techos de altura y grandes espacios. \nLa zona de día se abre desde todas las estancias al maravilloso jardín y \nagradables porches desde donde ya se ve el mar azul de la magnífica costa \ncatalana. La zona de noche c"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-88",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 88,
    "content": "uenta con una amplia suite con unas bonitas \nvistas al mar y a la ciudad de Barcelona y otros 2 dormitorios dobles que \ncomparten un baño completo. Esta excepcional vivienda se completa con salas \nadicionales de ocio o deporte, zona de servicio, dormitorio de invitados y un \ngran garaje para varios vehículos. Rodeada de un encantador jardín con \ngrandes palmeras y rodeada de césped natural y arboles maduros que rodean \nla casa, zona de barbacoa y una gran piscina privada de agua salina. Una \nmagnífica inversión para todo aquel que quiera ganar en calidad de vida y paz \nsin desconectar de la maravillosa ciudad de Barcelona, es perfectamente \nconectada por las principales autopistas y muy cerca de los mejores colegios \ninternacionales de la zona. ¿Te lo vas a perder?”  \n● moreInfo: \"Casa o chalet independiente  3 plantas  532 m² construidos  5 \nhabitaciones  4 baños  Parcela de 1.205 m²  Terraza y balcón  Plaza de garaje \nincluida en el precio  Segunda mano/buen estado  Armarios empotrados  \nTrastero  Orientación sur, oeste  Construido en 1997  Calefacción individual\" \n● address: \"CL, LLAÜT, 3, 0, T, OD, OS, ALELLA, Barcelona, 8328\" \n● price: 2.450.000 € \n● area: 532m² \n● nhabitacion"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-89",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 89,
    "content": "es: 5 \n67 \n\nJSON\nJSON\n● nbaños: 4 \n● nplantas: 3 \n● añoConstrucción: 1997 \nThe system applies the function shown in Figure 25. Once the comparison is done and \na similarity score is obtained for each variable, the weights assigned by SetHome in the \nback office are applied: \n \"weights\": { \n    \"title\": 0.05, \n    \"description\": 0.1, \n    \"moreInfo\": 0.1, \n    \"address\": 0.1, \n    \"price\": 0.15, \n    \"area\": 0.2, \n    \"nhabitaciones\": 0.05, \n    \"nbaños\": 0.05, \n    \"nplanta\": 0.05, \n    \"añoConstruccion\": 0.15 \n  } \n \nWith these weights, the system gives more importance to fields such as area, price, \nand year of construction, as they are considered more reliable for detecting duplicates. \nFields like title, description, or address complement the analysis but have less \ninfluence. \nAfter applying the similarity function, the system produces the following result: \n{ \n  \"propertyId\": \"666a08abfe8f054e3f24822b\", \n  \"score\": 0.91 \n} \n \nSince the score obtained is higher than 0.8, the system considers it a possible \nduplicate property. This match is automatically stored in the similarityMatrix, in the \n68 \n\nsimilarities field linked to the input property. In addition, since it is higher"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-90",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 90,
    "content": "than 0.9, it is \nalso saved in the potentialDuplicates record of each property. \nBelow, you can see the new property (see Figure 26) and the property that was already \nregistered (see Figure 27), showing how they are the same listing advertised by two \ncompanies. \n \nFigure 26: The incoming property image. Source: Advertisement Idealista [24]. \n \nFigure 27: Existing property image. Source: Advertisement Idealista [25]\n. \n \n69 \n\n7. Testing \nThis section describes the tools used to verify and evaluate the functionality of the \ndifferent features developed throughout the project (see Figure 28). \n \nFigure 28: Testing Process Flow. Source: Own elaboration. \n7.1. Postman \nThis tool (see Figure 29) has been essential for the development of all functionalities \nrelated to the endpoints. It is especially useful for verifying the system's behavior \nwithout the need to have the backoffice management part implemented. \nThe following figure shows an example of a GET request to the property/:id endpoint, \nwhere it can be seen how it returns the object corresponding to the property with the ID \n67f599bb007e487ffac5e31d. \nAlthough not shown in the image, another important aspect is security. Post"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-91",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 91,
    "content": "man allows \nmanually adding the necessary cookies, which facilitates verifying the correct operation \nof JWT token-based authentication. \n70 \n\n \nFigure 29: Using Postman example. Source: Own elaboration. \n7.2. Google Chrome \nDuring the backoffice verification process, tools focused on analyzing and monitoring \nthe application's runtime behavior were used. In this regard, the Google Chrome \nbrowser provided a suitable environment thanks to the features included in its \ndeveloper panel (see Figure 30). These tools allowed examining the code, inspecting \nthe HTML document structure, logging system messages through the console, and \nreviewing requests made to the backend. \nThe following figure shows the flow of requests sent to the backend when loading the \nproperties screen, which is very useful for visualizing whether the information is \nreturned correctly or if there are communication issues with the server. \n71 \n\n \nFigure 30: Using DevTools example. Source: Own elaboration. \n \n7.3. Tests performed by SetHome \nThroughout the entire development process, SetHome’s feedback has been essential, \nas the client is best positioned to test the system and identify not only technical errors"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-92",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 92,
    "content": "but also usability and user experience issues. To streamline testing and obtain more \nprecise feedback, it was decided that the client would be responsible for conducting UX \ntests. This way, they can evaluate whether the developed solution truly meets their \nexpectations and detect potential issues beyond just technical functionality. \nOnce the client completes the tests, they communicate any problems found so that \nthese can be analyzed and addressed, ensuring that the final product is as suitable and \nfunctional as possible. \n72 \n\n8. Project execution \nThis section analyzes various aspects related to the planning, execution, and \nevaluation of the project. First, it describes the tracking carried out using the Asana \ntool. Next, it examines the deviations from the initial plan, identifying their causes and \ntheir impact on deadlines and costs. Finally, it evaluates the degree of compliance with \nthe functional and non-functional requirements defined at the beginning of the project, \nclassifying their level of achievement and justifying partially implemented requirements. \n8.1. Task Tracking with Asana \nThroughout the development of the project, Asana has been a key tool for task"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-93",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 93,
    "content": "tracking \nand management. Its use allowed for clear prioritization of activities that provided the \nmost value, facilitating making decisions based on the impact and urgency of each \ntask. \nAdditionally, Asana offered a global view of the project's status at all times, enabling \nquick identification of progress and pending tasks. This visibility was crucial to \nmaintaining the initial planning. \nFigure 31, shown below, is a screenshot representing an intermediate state of the \nproject in Asana, where the task organization can be observed. \n \nFigure 31: Using Asana example. Source: Own elaboration. \n \n73 \n\n8.2. Planning and Budget Changes \nTable 14 shows the hours deviation and the final state of the project. Specifically the list \nof planned initial tasks are included with the initially assigned hours, the final hours \nused, and the status of each task. It can be seen that all tasks were completed despite \nthe challenges encountered. \nAdditionally, there was an increase of 10 hours in the total time spent on the project. \nBelow, the reason for this deviation is explained in detail, along with the problems \nencountered and how they were resolved. \n \nDescription Initial Hour Final H"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-94",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 94,
    "content": "our State \nPM1 - Define context and scope 24 24 Completed \nPM2 - Define time planning 22 22 Completed \nPM3 - Make budget and sustainability report 18 18 Completed \nPM4 - Prepare final document 26 26 Completed \nI1 - Requirement specification 15 15 Completed \nI2 - Database design 8 8 Completed \nI3 - Setup and learning service functionality 15 15 Completed \nD1 - Selection of locations 6 6 Completed \nD2 - Requesting Data from the Service and \nAnalysis 30 30 Completed \nD3 - Storing the Data 8 8 Completed \nP1 - Data normalization 40 40 Completed \nC1 - Implement logic 40 46 Completed \nV1 - Implement views to manage properties 18 18 Completed \nV2 - Implement Functionality Related to Property \nAddresses 12 12 Completed \nV3 - Implement Modal to View Cadastre Data 18 18 Completed \nV4 - Implement Component for Quick Property \nView 20 22 Completed \nV5 - Implement property filter 10 10 Completed \nF1 - Assign users to properties 10 10 Completed \nF2 - Add Button to Download Excel 25 25 Completed \nF3 - Implementing functionality related to \nmanaging property states 12 12 Completed \nF4 - Implementation of Notifications for the User 12 12 Completed \n74 \n\nA1 - Automate the process 20 20 Completed \nA2"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-95",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 95,
    "content": "- Update downloading and cadastre data 4 6 Completed \nDT - Documentation and tracking 120 120 Completed \nMT - Meeting 7 7 Completed \nTotal hours of the project 540 550  \nTable 14:The project final deviation \n \nThroughout the project, various difficulties and setbacks were encountered, leading to \ndelays in some planned tasks and requiring others to be redefined. Additionally, some \nerrors arose from a lack of experience, although these did not impact the established \ntimelines. The most significant issues that caused deviations were: \nC1 - Change in the cadastral search strategy \nThis delay is related to the process of linking a property with its corresponding record in \nthe cadastre. Initially, the task was approached by searching for matches based on \nlocality, year of construction, and surface area. This approach produced some correct \nmatches, so it was decided to allow SetHome to test the algorithm. \nOnce their feedback was received, the results were analyzed. Although some matches \nwere acknowledged as correct, SetHome considered that the percentage of accurate \nresults was too low, so it was concluded that the algorithm needed to be modified. \nA new algorithm was developed t"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-96",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 96,
    "content": "hat considered locality, year of construction, surface \narea (usable or built), and plot area. The new criteria required a mandatory match in \nlocality and at least two of the remaining three variables. \nThis required redoing the entire process to implement the new algorithm, which \nresulted in approximately 6 additional hours of work for this task. \nV4 - Add new functionality \nThis delay is related to the implementation of the side panel, designed to quickly \ndisplay the most relevant information about a property. In the first version, when it was \npresented to SetHome, they pointed out the absence of an important feature: they \nwanted to be able to modify the information directly from that view, as it involved \nimportant data. \nThis required adjusting the component’s logic to allow in situ editing and automatically \nsave changes when the panel was closed. The adaptation only required about 2 \n75 \n\nadditional hours of work, which were spent modifying the necessary fields and \nimplementing the save functionality. \nA2 - Synchronization issue \nThis error is related to the import of new data from the cadastre. The functionality had \nalready been implemented before the start of the pro"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-97",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 97,
    "content": "ject, so it was only adapted to \ntrigger the download and linking process with the new data. \nIn the initial version, it was confirmed that the process executed correctly, but it wasn’t \nverified whether the new imported data was being used, in other words, whether the \nsystem was still using outdated cadastre data. \nWhen SetHome tested the process, they noticed that after uploading new data, it \nwasn’t being used. This became evident when, after updating the data and running the \nprocess automatically the following day, new matches appeared when there shouldn't \nhave been any, since the update had taken place the day before. \nAfter analyzing the issue, the root cause was identified as an incorrect execution order \nof the update and import processes: the new data was being uploaded, but the system \nbegan the update first, recovering the previous version. \nAlthough the error was relatively simple, identifying it required reviewing the entire flow \nand performing step-by-step debugging, which took approximately 2 additional hours of \nwork. \nBelow is a table similar to Table 15, which includes the columns \"Deviation in hours\" \nand \"Deviation in euros.\" This table shows how the final b"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-98",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 98,
    "content": "udget was organized and how \nthe 10 additional hours mentioned previously resulted in an extra cost of 272.69€. \nThe breakdown of these hours is as follows: 6 additional hours in the backend, 2 hours \nand 30 minutes in the frontend, and 1 hour and 30 minutes dedicated to testing tasks. \n \nDescription Hour \nCost (€) Total (€) \nDeviation (h) \nDeviation (€) \nPM1 - Define context and scope 24 560.16 \n2,100.60 0.00 0.00 \nPM2 - Define time planning 22 513.48 \nPM3 - Make budget and \nsustainability report 18 420.12 \nPM4 - Prepare final document 26 606.84 \nI1 - Requirement specification 15 350.10 973.17 0.00 0.00 \n76 \n\nI2 - Database design 8 186.72 \nI3 - Setup and learning service \nfunctionality 15 436.35 \nD1 - Selection of locations 6 158.28 \n1,234.95 0.00 0.00 \nD2 - Requesting Data from the \nService and Analysis 30 843.95 \nD3 - Storing the Data 8 232.72 \nP1 - Data normalization 40 1,163.60 1,163.60 0.00 0.00 \nC1 - Implement logic 46 1,338.14 1,338.14 6.00 174.54 \nV1 - Implement views to manage \nproperties 18 460.20 \n2,011.57 2.00 45.01 \nV2 - Implement Functionality \nRelated to Property Addresses 12 304.20 \nV3 - Implement Modal to View \nCadastre Data 18 457.11 \nV4 - Implement Component for"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-99",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 99,
    "content": "Quick Property View 22 551.03 \nV5 - Implement property filter 10 239.03 \nF1 - Assign users to properties 10 255.29 \n1,573.87 0.00 0.00 \nF2 - Add Button to Download Excel 25 697.82 \nF3 - Implementing functionality \nrelated to managing property states 12 310.38 \nF4 - Implementation of Notifications \nfor the User 12 310.38 \nA1 - Automate the process 20 581.80 \n743.17 2.00 53.14 \nA2 - Update downloading and \ncadastre data 6 161.37 \nDT - Documentation and tracking 120 2,946.39 2,946.39 0.00 0.00 \nMT - Meeting 7 682.08 682.08 0.00 0.00 \nTotal hours of the project 550 \n \n \n Total human cost of the project  14,767.54 \nTotal deviation  10.00 272.69 \nShow the budget calculations \nTable 15:  The budget project final deviation \n8.3. Level of satisfaction of requirements \nThis section evaluates the level of achievement of the requirements defined at the \nbeginning of the project. First, the functional requirements are analyzed, with particular \nattention given to the reasons why some were not achieved or were only partially \nachieved. Subsequently, the non-functional requirements are reviewed following the \nsame approach. \n77 \n\nIt is important to note that three levels of achievement have bee"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-100",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 100,
    "content": "n defined: completed, \npartial, and not achieved. \n● The completed level is assigned to those requirements that have been achieved \naccording to SetHome’s evaluation. \n● The partial level corresponds to requirements that have been partially \nimplemented but are considered to have deficiencies by SetHome. \n● The not achieved level refers to those requirements that, according to \nSetHome’s assessment, have not been achieved. \nFunctional requirements \nThe vast majority of the requirements have been satisfied by SetHome, meeting what \nwas established in their description. However, there are two requirements that have not \nbeen completed with the same level of success. \n \nFR6 stated that all data should be manually validated before updating the database. \nHowever, it was considered more efficient to apply this validation only to certain critical \nfields, such as the address and potential duplicates. In this way, it is not necessary to \nvalidate attributes like the number of bathrooms or the number of floors, as these are \ntheoretically constant values. If they change during the property’s follow-up, they can \nalways be manually corrected. \n \nOn the other hand, FR7 was intended to allow"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-101",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 101,
    "content": "the reversal of manually introduced \nerrors. Although it is possible to modify a property as many times as needed, there is \nno automatic history of previous values unless the user remembers and manually \nre-enters them. In other words, if the number of bathrooms is changed and then one \nwants to revert to the previous value, it will only be possible if that value is known. For \nfields that have a history, such as price, it is possible to consult previous values. \nHowever, when restoring a previous value, a new entry is generated in the history, \nwhich can distort visualizations like price evolution charts. \n \nIt was decided not to implement a full versioning system because it would involve \nstoring a large amount of data for each property, which could exponentially multiply the \ninformation over time, causing inefficiencies and increased complexity in data \nmanagement. \n \n \n78 \n\nCode Description \nLevel of \nachievement \nFR1 \nThe downloading process must be executed automatically at configurable intervals set \nby the system administrator. \nCompleted \nFR2 \nThe application must allow comparing properties with cadastral data, requiring a \nmandatory match on the locality and, \nin additi"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-102",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 102,
    "content": "on, a match on at least two of the following attributes: construction year, \nsurface area, or parcel number. \nCompleted \nFR3 \nWhen cadastral data is updated, the system must automatically compare the new \ninformation with the existing records and \nupdate them accordingly. \nCompleted \nFR4 \nThe interface must allow the user to define an error margin for data comparison \nbetween loading and cadastral records. \nCompleted \nFR5 \nThe interface must include a section where the user can view and correct detected \ndata errors. \nCompleted \nFR6 \nThe user must be able to validate and manually approve changes before updating the \ndatabase. \nPartial \nFR7 \nThe system must allow the reversal of changes in case a manual correction introduces \nerrors. \nNot achieved \nFR8 \nThe interface must display a table with key property data, including reference, name, \nproperty type, location, price, \nsurface area, address, advertiser, and creation date. \nCompleted \nFR9 It must enable the display of associated images within the table. Completed \nFR10 The interface must include action buttons (for example: editing, deleting). Completed \nFR11 \nThe interface must include an advanced filtering system, allowing users"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-103",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 103,
    "content": "to search for \nproperties by reference, title, price, \nsurface area, property type, year of construction, status, location, advertiser type, and \nassigned user. \nCompleted \nFR12 \nFilters must be applicable in combination and should include sorting options \n(ascending/descending) for different attributes. \nCompleted \nFR13 The system must allow selecting all properties that match the applied filters. Completed \nTable 16: Levels of achievement of functional requirements \n \n \nNon-Functional requirements \nRegarding the non-functional requirements, only NFR4 could not be achieved. This \nrequirement stated that, if the processed data arrived with a different structure, for \nexample, if the field was previously called nBaños and is now called numeroBaños, the \nsystem should be able to adapt automatically. It also considered the possibility of \nautomatically incorporating new fields if additional information was provided in the data. \n \n79 \n\nRegarding changes in nomenclature, no simple solution has been found to effectively \nimplement this adaptability. Since this is the first version of the system, it was decided \nnot to invest additional resources in a problem that is not considered a sho"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-104",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 104,
    "content": "rt-term \npriority. \n \nOn the other hand, in cases where new information is added, it is not incorporated \nautomatically. However, thanks to the use of a database like MongoDB, it is possible to \neasily modify the structure of the documents to store new fields when necessary. \n \nCode Description \nLevel of \nachievement \nNFR1 The user must be able to access the information with the fewest clicks Completed \nNFR2 Data must be accessible during business hours (9am - 8pm) Completed \nNFR3 It must be possible to launch the downloading process every 24 hours Completed \nNFR4 \nIt must be able to adapt to changes in the distribution of information \nreturned \nNot achieved \nTable 17: Levels of achievement of non-functional requirements \n80 \n\n9. Legal aspects \nIn this project, it is essential to consider legal aspects related to data protection, the \nuse of external services, and the licenses of the technologies used.  \n9.1. Laws applicable to the project \nThe system stores information about properties and users, which involves the \nprocessing of potentially personal data provided by an external service and, therefore, \nits use must be responsible and compliant with current legislation. \nThe data"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-105",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 105,
    "content": "used comes from two external sources: one external company providing data \non real estate advertisements, and another that provides cadastral data. In both cases, \nthe data have been employed exclusively for the purpose of analyzing the real estate \nmarket. The use of these data complies fully with all applicable regulations in Spain, \nand their use is legally permitted for market analysis purposes. \nThe regulations related to data protection to take into account are: \n● REGULATION (EU) 2016/679 OF THE EUROPEAN PARLIAMENT AND OF \nTHE COUNCIL of April 27, 2016 relative to the protection of natural persons \nwith regard to the processing of personal data and to the free circulation of this \ndata and by which Directive 95/46/EC (Regulation general data protection).[26] \n● Spanish Organic Law 3/2018, of December 5, on the protection of personal \ndata and guarantee of digital rights. \nIn these laws the limitations stated are: \n● In case of importing personal data, report it or consider anonymizing the \ninformation. In fact, the data that is used and captured in this project from \nexternal services do not include personal data that allow the identification of \npeople.  \n● The purpose has"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-106",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 106,
    "content": "to be legitimate. One of the possible uses is market analysis.  \n● Do not collect more data than the necessary and nor sensitive data. During the \nproject it was decided the data to be collected in order to not include sensitive \ninformation.  \nThe regulations regarding external services. The company in which the author of this \nproject works has carefully considered all relevant legal and regulatory requirements \nregarding the use of external data services. Contracts with the external company \n81 \n\ninclude clear terms on data ownership, usage rights, and confidentiality. Additionally, \ncompliance with data protection laws, including the GDPR, has been included in the \ncontract. Also, measures have also been taken to verify the quality and reliability of the \ndata, as well as to maintain its security throughout the import process. Finally, the \nlimitations about the use of the data has been also included in the contracts.  \n9.2. Licenses \nThe project uses open-source technologies, each subject to its own license. These \nlicenses generally allow free use of the tools as long as their terms and conditions are \nrespected. In this case, there are no direct limitations, since the projec"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-107",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 107,
    "content": "t is not being \ndistributed commercially. \nThe user interface has been developed using React, and the server with Node.js, both \nunder the MIT [27] license, which allows free use, modification, and distribution of the \ncode.  \nThe database used is MongoDB, which is licensed under the SSPL [28], a license that \npermits unrestricted internal use but imposes stricter conditions if the software is \noffered as a service to third parties. Since the system developed is going to be used \ninternally these stricter conditions do not apply. \n \n \n82 \n\n10. Sustainability \nAfter conducting the test on environmental knowledge within my professional sector, I \nhave been able to identify areas where I have more expertise and those where I need \nto deepen my knowledge. Regarding the social, economic, and environmental issues \nfacing today's society, I believe I have a fairly general understanding of the situation, \nbut not a thorough knowledge of their specific effects on my professional field. \nOne of the areas where I feel I lack the most knowledge is the environmental impact of \nthe products and services within my sector. I do not have a strong understanding of the \nfactors that contribute to pol"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-108",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 108,
    "content": "lution, emissions, or waste generation in relation to my \nprofession. Therefore, I should seek more information on what these factors are and \nhow to reduce this impact in order to incorporate more sustainable practices into my \nwork. \nOn the other hand, I have also realized that I have not paid much attention to the \nrelationship between my professional activities and health, safety, and social justice. \nThere are many aspects, such as accessibility, equality, and transparency, that I have \noverlooked until now, but I believe it is important to integrate them more into my way of \nworking. \nIn contrast, I feel more confident in the economic aspect. I am familiar with tools and \nmethods to assess the economic viability of projects and manage resources efficiently. \nThis enables me to make informed decisions and optimize the processes I work on. \nOverall, this exercise has helped me see that, while I have a solid foundation in \neconomic management, I need to deepen my knowledge in areas related to \nsustainability and social impact. I believe that improving in these areas will allow me to \nhave a more balanced and responsible perspective on my work \n10.1. Economic \nReflection on the c"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-109",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 109,
    "content": "ost you have estimated for the completion of the project \nTo estimate the cost of the project, personnel costs, material resources, contingencies, \nand incidents have been taken into account. All of this is based on the estimation of the \nworking hours required to complete each task. It has been calculated that the project \nwill cost 14,494.85€, of which 10% is allocated to unforeseen events. I consider this to \nbe a very reasonable cost given the characteristics of the project to be developed. \n83 \n\nHow are currently solved economic issues related to the problem that you want \nto address? \nCurrently, the problem is addressed by using queries in an Excel sheet containing all \nthe properties registered in the cadastre and comparing the results one by one with the \nlistings on the platform. This process is time-consuming and requires a significant \ninvestment of working hours by employees. \nHow will your solution improve economic issues with respect to other existing \nsolutions? \nThis solution automates the process and facilitates data visualization, significantly \nreducing all economic expenses related to the property selection process. (Having an \nemployee review an Excel sheet gen"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-110",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 110,
    "content": "erates two types of costs: on one hand, their \nsalary, and on the other, electricity consumption.) \n \n10.2. Environmental \nHave you estimated the environmental impact of the project? \n \nA detailed estimation of the project's environmental impact has not been carried out. \nHowever, it is evident that the manual process of an employee detecting a new \nproperty on a platform, checking if it is already registered, and, if not, searching for it in \nthe cadastre Excel file until it is found, is much more energy-intensive than a \ndownloading process. \n \nDid you plan to minimize its impact, for example, by reusing resources? \n \nYes, by carrying out the project in a coworking space, resources such as screens are \nreused among different companies. On the other hand, at the programming level, the \nproject could be implemented with just two roles: a project manager and a full-stack \nprogrammer. This way, four laptops would not be needed, reducing future waste \ngenerated once these devices reach the end of their useful life. \n \nHow is currently solved the problem that you want to address? And how will \nyour solution improve the environment with respect to other existing solutions? \n \n84 \n\nCurre"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-111",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 111,
    "content": "ntly, environmental issues in computing are often addressed by using renewable \nenergy and reusing material resources. That said, the environmental improvement \noffered by this project is related to the usage time of these material resources, as \nreducing processing times leads to lower energy consumption. \n \n10.3. Social \nWhat do you think you will achieve -in terms of personal growth- from doing this \nproject? \n \nThis project will provide me with hands-on experience in developing automated \nsystems. Additionally, it will enhance my project management skills, as I will need to \ncoordinate tasks, resources, and time to meet the objectives. It will also help me better \nunderstand client needs and how to deliver technological solutions that add value to \ntheir businesses. \n \nHow is currently solved the problem that you want to address? And how will your \nsolution improve the quality of life with respect to other existing solutions? \n \nCurrently, the problem is addressed by investing more hours of workers' time in a \ntedious process, such as comparing data. Therefore, the solution proposed by this \nproject is to make employees' work easier by eliminating these repetitive and \nmechanic"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-112",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 112,
    "content": "al tasks, allowing them to focus on more rewarding tasks that make them feel \nmore fulfilled. \n \nIs there a real need for the project? \n \nYes, there is a real need for the project. The SetHome agency requires a solution that \nenables it to carry out more efficient and detailed market analysis. By automating the \ndata processing and integrating it with its internal systems, the agency will be able to \nidentify trends, compare property characteristics more effectively, and generate more \ncompetitive and well-informed offers. This improved analytical capacity will support \nbetter strategic decision-making and allow the company to adapt more quickly to \nchanges in the real estate market. \n \n85 \n\n11. Conclusions and future work \nThis chapter presents the conclusions of the project, addressing the technical skills \ndeveloped during the project, as well as the connection between the work and the \ndegree and specialization. Additionally, it reflects on the personal experiences and \nlessons learned, and proposes possible future lines of work that could continue and \nimprove the project. \n11.1. Technical skills worked on \nCES1.1: To develop, maintain and evaluate complex and/or critical soft"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-113",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 113,
    "content": "ware \nsystems and services. Throughout the development of the project, various skills \nrelated to the field of software engineering have been applied. Regarding the CES1.1 \ncompetency, work has been done on the development and maintenance of a software \nsystem of a certain level of complexity, focused on properties management and \nanalysis. Although it is not a critical system, it has been necessary to carry out careful \nplanning and to ensure the reliability and proper functioning of the different components \nimplemented. Among them, the construction of a module for processing and \nnormalizing properties data provided by an external service, as well as a system for the \nautomatic detection of duplicate properties, based on a similarity analysis between \nattributes such as title, address, price, or area.         \nCES1.5: To specify, design, implement and evaluate databases. On the other hand, \nthe CES1.5 competency has played a particularly important role, since a fundamental \npart of the project has involved adapting, designing, and implementing new collections \nin a MongoDB database. This database stores key information for the system, such as \nproperties, cadastre data, configur"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-114",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 114,
    "content": "ations, and similarity matrices. Throughout the \ndevelopment, decisions have been made regarding the structure of the documents, \nincluding the representation of each property's evolution history and the linking \nbetween properties and assigned users. In addition, aspects related to query efficiency \nhave been evaluated by adding indexes to the critical collections. \nCES1.2: To solve integration problems in function of the strategies, standards \nand available technologies and CES2.1: To define and manage the requirements \nof a software system. Regarding competencies CES2.1 and CES1.2, related \nrespectively to requirements definition and management, and to the integration of \nsoftware components. Although the system started with a good initial definition, it was \nnecessary to refine the requirements together with the client (SetHome). Specific \n86 \n\naspects were defined more precisely, such as the linking between the cadastre and \nproperties, or the comparison criteria between properties. To meet these requirements, \ntechnologies were integrated, such as string comparison libraries, or the client was \ngiven the freedom to choose the strategy. \n11.2. TFG’s connection to the degree an"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-115",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 115,
    "content": "d \nspecialization \n \nThis section evaluates the contributions that the courses from the degree and the \nspecialization in Software Engineering have provided to the development of this \nproject. \nFirst, it was necessary to carry out a requirements analysis and evaluate the market \nenvironment, as well as the existence of tools that could already cover the desired \nfunctionalities. To perform this task, the courses in Requirements Engineering (ER) and \nSoftware Architecture (AS) were essential, as they made it possible to properly \nstructure the data, define use cases, and document the system in a clear and \norganized way. \nSecondly, it was essential to plan the project and select an appropriate working \nmethodology. In this regard, the courses Software Project Management (GPS) and \nSoftware Engineering Project (PES) were key, as they provided the necessary \nknowledge to organize the development efficiently. \nThirdly, the project faced complex data processing tasks, which required writing \noptimized queries, using indexes, and parallelizing the code to improve performance. \nTo overcome these challenges, the contents of Parallel Computing (PAR), Database \nDesign (DBD), and Programming"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-116",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 116,
    "content": "Project (PROP) were crucial. \nFourthly, a REST API and its corresponding web interface were developed to cover the \nrequired functionalities. In this case, the courses Web Applications and Services \n(ASW), Interaction and Interface Design (IDI), and once again PES were especially \nuseful due to their practical and multidisciplinary approach. \nFinally, it is worth noting that courses like Information Systems Concepts (CSI) have \nalso been very helpful, even though they do not focus directly on the technical aspects \nof development. This course provided a greater understanding of the business, which \nwas essential when planning features with the client’s needs in mind. Thanks to this, \n87 \n\nbetter alignment was achieved between the company’s (SetHome) needs and the \nproposed technical solutions, reaching effective agreements in an agile manner. \n \n11.3. Personal conclusions \nAs the developer of this project, it has been very rewarding to see how, starting from an \ninitial lack of experience with technologies like React.js, Node.js, and MongoDB, I have \nbeen able to successfully complete a functional, usable, and technically complete \nsystem. Throughout the development, I learned how"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-117",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 117,
    "content": "to manage a real project, \nunderstand the client’s needs properly, and turn them into effective solutions. This \nprocess allowed me to consolidate the knowledge acquired during my studies and to \nsee how many of those academic foundations can be applied in a professional \nenvironment, even if they sometimes need to be adapted. \nHowever, it is important to recognize that the original idea of the project has been \npartially surpassed by the emergence of new technologies, especially generative \nartificial intelligence. Nowadays, this kind of tool allows the processing of large volumes \nof information in a contextualized way, adapting to format and language, and offering \nmore accurate and flexible responses than those obtained through traditional string \ncomparison methods. \nThe client, Owius, and I agree that the project could evolve into an AI-based solution, \nwhich would significantly increase its reliability by reducing dependence on the input \ndata format and solving issues caused by the variability of natural language. In \naddition, technologies such as image-based search or semantic processing would \nbring substantial added value to the tool. \nAlthough the project met the func"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-118",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 118,
    "content": "tional requirements defined at the beginning, the rapid \nprogress of the sector has changed the client's focus toward more innovative solutions. \nAs a result, the developed product has taken a back seat, not due to a lack of quality, \nbut because of a technological paradigm shift. It may seem frustrating that such \nextensive work does not lead to a long-term solution, but this is a reality inherent to the \nworld of software development, especially in a context of constant technological \ndisruption. \nFrom a personal perspective, this project has been a very valuable experience. It has \nallowed me to work with modern technologies, face real challenges, and better \n88 \n\nunderstand the dynamics between client, developer, and product. It has been a key \nstep in my development as an engineer. \n \n11.4. Future work \nFor a possible future development of the project, the next natural step would be to turn \nthe tool into an intelligent platform capable of processing and analyzing properties \nusing artificial intelligence models. Below are some key ideas that could shape the \nfuture roadmap: \n● Smart processing of input data \nUse language models such as Llama or similar to interpret and standa"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-119",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 119,
    "content": "rdize \nproperty descriptions, regardless of language, structure, or format, allowing \nbetter normalization and semantic understanding of the data. \n● Advanced semantic comparison \nReplace string similarity-based systems with embeddings and machine learning \nmodels that understand the meaning behind the descriptions, eliminating \ninconsistencies in property comparison. \n● Existing interface as a solid foundation \nTake advantage of the interface already developed in React.js as a starting \npoint, integrating AI modules without the need to completely redesign the \nsystem. \nThis approach would not only update the project to current standards, but also position \nit as a competitive and innovative tool within the sector. Despite everything, the project \nstill has great potential, as long as it is approached with an open mindset toward the \nintegration of new technologies. \n \n89 \n\nReferences \n \n[1]  Idealista. | datos.gob.es. (22/02/2025)[online]. \nhttps://datos.gob.es/es/casos-exito/idealista \n[2] El municipio en cifras. Alella (Maresme). | Idescat. (22/02/2025)[online]. \nhttps://www.idescat.cat/emex/?id=080039&lang=es \n[3] Cadastre | Dictionary Cambridge. (05/04/2025)[online]. \nhttps://"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-120",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 120,
    "content": "dictionary.cambridge.org/dictionary/english/cadastre \n[4] Kanban en el desarrollo de software | ClockKanban. (23/02/2025)[online] \nhttps://clockkanban.com/es/kanban-en-el-desarrollo-de-software-mejores-practi\ncas/ \n[5] Gestión del trabajo. | Slack. (23/02/2025)[online] \nhttps://slack.com/intl/es-es \n[6] Gestiona las tareas de tu equipo en línea | Asana. (23/02/2025)[online] \nhttps://asana.com/es \n[7] Git solution for teams using Jira. | Bitbucket. (23/02/2025)[online] \nhttps://bitbucket.org/product/ \n[8]  Salario en España - Salario Medio. | Talent.com. (07/03/2025)[online] \n https://es.talent.com/salary \n[9] Nuestros planes y precios de coworking | Cloudworks. (07/03/2025)[online] \nhttps://wearecloudworks.com/plan/ \n[10] Portátil HP | HP Store España. (07/03/2025)[online] \nhttps://www.hp.com/es-es/shop/product.aspx?id=7P6V8EA&opt=ABE&sel=NTB \n[11] ¿Cuántos días laborables en el año 2025? | (07/03/2025)[online] \nhttps://www.dias-laborables.es/cuantos_dias_laborables_en_ano_2025_Catalu\n%C3%B1a.htm \n[12] Functional requirements examples and templates | Jama Software  \n(18/03/2025)[online] \nhttps://www.jamasoftware.com/requirements-management-guide/writing-require\nment \n[13] What is a"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-121",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 121,
    "content": "virtual private server (VPS)? | Google Cloud.(18/05/2025)[online] \nhttps://cloud.google.com/learn/what-is-a-virtual-private-server \n[14] OVHCloud. | OVHcloud. (18/05/2025)[online] \nhttps://www.ovhcloud.com/en/ \n[15] What is NGinx? | Kinsta.(18/05/2025)[online]  \nhttps://kinsta.com/knowledgebase/what-is-nginx/ \n90 \n\n[16] SPA (Single-page application) | MDN Web Docs. (18/05/2025)[online]  \nhttps://developer.mozilla.org/en-US/docs/Glossary/SPA \n[17] MongoDB | MongoDB. (18/05/2025)[online]  \nhttps://www.mongodb.com/ \n[18]  MVC Design pattern | GeeksforGeeks. (18/05/2025)[online]  \nhttps://www.geeksforgeeks.org/mvc-design-pattern/ \n[19] Don’t repeat yourself(DRY)  | GeeksforGeeks. (18/05/2025)[online]  \nhttps://www.geeksforgeeks.org/dont-repeat-yourselfdry-in-software-developmen\nt/?ref=next_article \n[20] Admin template | Metronic by Keenthemes. (18/05/2025)[online]  \nhttps://keenthemes.com/metronic \n[21] Dumb & smart components in React | Medium.(18/05/2025)[online]  \nhttps://medium.com/@abubakarmemon/dumb-smart-components-in-react-0d19\ne2653398 \n[22] Casa en venta en urbanización exclusiva Can Teixidó | Premium Houses.  \n(07/06/2025)[online] \nhttps://www.premiumhouses.es/alella/casa-e"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-122",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 122,
    "content": "n-venta-urbanizacion-exclusiva-ca\nn-teixido-con-vistas-al-mar-y-al-skyline-de-barcelona \n[23] Dice-Sørensen coefficient | Wikipedia. (16/06/2025)[online] \nhttps://en.wikipedia.org/wiki/Dice-S%C3%B8rensen_coefficient \n[24] Casa o chalet independiente en venta en Can Teixido-Can Sors | idealista.com \n (07/06/2025)[online] \nhttps://www.idealista.com/inmueble/88419780/ \n[25] Casa o chalet independiente en venta en Can Teixido-Can Sors | idealista.com \n (07/06/2025)[online] \nhttps://www.idealista.com/inmueble/40123885/ \n[26] Reglamento (UE) 2016/679 del Parlamento Europeo y del Consejo. \n(04/05/2016)[en línea] \nhttps://www.boe.es/doue/2016/119/L00001-00088.pdf \n[27] The MIT license.  | Open Source Initiative.(18/05/2025)[online]  \nhttps://opensource.org/license/mit \n[28] Server Side Public License (SSPL). | MongoDB (18/05/2025)[online]  \nhttps://www.mongodb.com/legal/licensing/server-side-public-license \n \n91 \n\nJavaScript\nAppendixes \n \nexport async function detectLocalidad(ubicacion, titulo, localidades) { \n  const words = Array.from( \n    new Set( \n      ubicacion \n        ?.replace(/\\d+/g, \"\") \n        .normalize(\"NFD\") \n        .replace(/[\\u0300-\\u036f]/g, \"\") \n        .split(/(?<!^)"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-123",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 123,
    "content": "(?=[A-Z])|\\s+/) \n        .map((word) => word.toLowerCase()) \n        .concat( \n          titulo \n            ?.replace(/\\d+/g, \"\") \n            .normalize(\"NFD\") \n            .replace(/[\\u0300-\\u036f]/g, \"\") \n            .split(/(?<!^)(?=[A-Z])|\\s+/) \n            .map((word) => word.toLowerCase()) \n        ) \n    ) \n  ).filter((item) => item); \n \n  let maxSimilarity = -1; \n  let mostSimilarLocalidad = null; \n  let matchesTotales = {}; \n  localidades.forEach((localidad) => { \n    if (localidad.takeIntoAccount) { \n      matchesTotales[localidad.fullName] = 0; \n    } \n  }); \n  words.forEach((word) => { \n    localidades.forEach((localidad) => { \n      if (localidad.takeIntoAccount) { \n        let localidadesDivFullName = localidad.fullName \n          ?.normalize(\"NFD\") \n          .replace(/[\\u0300-\\u036f]/g, \"\") \n          .split(/(?<!^)(?=[A-Z])|\\s+/); \n        let similarity = 0; \n        localidadesDivFullName.forEach((localidadDiv) => { \n          similarity = calculateSimilarityStrings( \n            word, \n            localidadDiv.toLowerCase() \n          ); \n          matchesTotales[localidad.fullName] += similarity; \n        }); \n      } \n92 \n\nJavaScript\n    }); \n  }); \n  for (c"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-124",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 124,
    "content": "onst key in matchesTotales) { \n    if (matchesTotales.hasOwnProperty(key)) { \n      let localidadesDivFullName = key?.split(/(?<!^)(?=[A-Z])|\\s+/); \n      matchesTotales[key] = matchesTotales[key] / \nlocalidadesDivFullName.length; \n    } \n  } \n  for (const [localidad, similarity] of Object.entries(matchesTotales)) \n{ \n    if (similarity > maxSimilarity) { \n      maxSimilarity = similarity; \n      mostSimilarLocalidad = localidades.find( \n        (loca) => loca.fullName === localidad \n      ); \n    } \n  } \n \n  if (mostSimilarLocalidad === null || mostSimilarLocalidad === \"\") { \n    mostSimilarLocalidad = localidades[0]; \n  } \n \n  return mostSimilarLocalidad; \n} \n \n// Helper function to calculate similarity between strings \nexport function calculateSimilarityStrings(str1, str2) { \n  let matches = 0; \n \n  for (let i = 0; i < str1.length && i < str2.length; i++) { \n    if (str1[i] === str2[i]) matches++; \n  } \n  let aux = matches / Math.max(str1.length, str2.length); \n  return aux == 1; \n} \nFigure 1 Appendix:  Code to link locations with properties. Source: Own elaboration. \n \n \nexport async function findSimilarCadastralProperties(data) { \n  const config = await getConfiguration();"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-125",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 125,
    "content": "const añoConstruccionError = config.errorFactors.añoConstruccionError; \n  const parcelaError = config.errorFactors.parcelaError; \n93 \n\n  let lista = []; \n  // Normalize input data \n  const localidad = data.localidad \n    ?.toUpperCase() \n    .normalize(\"NFD\") \n    .replace(/[\\u0300-\\u036f]/g, \"\"); \n  const checkStreet = localidad?.checkStreet ? localidad.checkStreet : \nfalse; \n  const area = parseFloat(data.area); \n \n  let areaError; \n  if (area % 10 === 0) areaError = config.errorFactors.areaErrorIfExact; \n  else areaError = config.errorFactors.areaError; \n  const añoConstruccion = parseInt(data.añoConstruccion, 10); \n  const street = data.street; // We'll normalize the street name in the \nfindBestStreetMatch function \n  let superficieConstruida = parseInt(data.construidos, 10); \n  let superficieUtil = parseInt(data.utiles, 10); \n  let parcela = parseInt(data.parcela, 10); \n \n  let possibleMatches = []; \n  let encontrado = false; \n  // 1. Municipio + Año + Superficie Construida + Parcela \n  if ( \n    !encontrado && \n    localidad && \n    añoConstruccion && \n    superficieConstruida && \n    parcela \n  ) { \n    const superficieConstruidaInt = parseInt(data.construidos, 10); \n    con"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-126",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 126,
    "content": "st parcelaInt = parseInt(data.parcela, 10); \n    const condicion = { \n      nombreMunicipio: localidad, \n      anoAntiguedadBienInmueble: añoConstruccion, \n      superficieElementosConstructivos: superficieConstruidaInt, \n      superficieAsociadaInmueble: parcelaInt, \n    }; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 2. Municipio + Año + Superficie Útil + Parcela \n  if ( \n    !encontrado && \n94 \n\n    localidad && \n    añoConstruccion && \n    superficieUtil && \n    parcela \n  ) { \n    const superficieUtilInt = parseInt(data.utiles, 10); \n    const parcelaInt = parseInt(data.parcela, 10); \n    const condicion = { \n      nombreMunicipio: localidad, \n      anoAntiguedadBienInmueble: añoConstruccion, \n      superficieElementosConstructivos: superficieUtilInt, \n      superficieAsociadaInmueble: parcelaInt, \n    }; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 3. Municipio + Año + Superficie Const"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-127",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 127,
    "content": "ruida \n  if (!encontrado && localidad && añoConstruccion && \nsuperficieConstruida) { \n    const superficieConstruidaInt = parseInt(data.construidos, 10); \n    const condicion = { \n      nombreMunicipio: localidad, \n      anoAntiguedadBienInmueble: añoConstruccion, \n      superficieElementosConstructivos: superficieConstruidaInt, \n    }; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 4. Municipio + Año + Superficie Útil \n  if (!encontrado && localidad && añoConstruccion && superficieUtil) { \n    const superficieUtilInt = parseInt(data.utiles, 10); \n \n    const condicion = { \n      nombreMunicipio: localidad, \n      anoAntiguedadBienInmueble: añoConstruccion, \n      superficieElementosConstructivos: superficieUtilInt, \n    }; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n95 \n\n      encontrado = true; \n    } \n  } \n \n  // 5. Municipio + Año + Parcela \n  if (!encontrado && localidad && añoConstruccion && parcela) { \n    const parcelaInt = pars"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-128",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 128,
    "content": "eInt(data.parcela, 10); \n    const condicion = { \n      nombreMunicipio: localidad, \n      anoAntiguedadBienInmueble: añoConstruccion, \n      superficieAsociadaInmueble: parcelaInt, \n    }; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 6. Municipio + Superficie Construida + Parcela \n  if (!encontrado && localidad && superficieConstruida && parcela) { \n    const superficieConstruidaInt = parseInt(data.construidos, 10); \n    const parcelaInt = parseInt(data.parcela, 10); \n    const condicion = { \n      nombreMunicipio: localidad, \n      superficieElementosConstructivos: superficieConstruidaInt, \n      superficieAsociadaInmueble: parcelaInt, \n    }; \n    lista.push(JSON.stringify(condicion)); \n \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 7. Municipio + Superficie Útil + Parcela \n  if (!encontrado && localidad && superficieUtil && parcela) { \n    const superficieUtilInt = parseInt(data.utiles, 10); \n    const parcelaInt = parseInt(data.pa"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-129",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 129,
    "content": "rcela, 10); \n    const condicion = { \n      nombreMunicipio: localidad, \n      superficieElementosConstructivos: superficieUtilInt, \n      superficieAsociadaInmueble: parcelaInt, \n    }; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n96 \n\n      encontrado = true; \n    } \n  } \n \n  // 8. Municipio + Año error + Superficie Construida + Parcela \n  if ( \n    !encontrado && \n    añoConstruccionError > 0 && \n    localidad && \n    añoConstruccion && \n    superficieConstruida && \n    parcela \n  ) { \n    const superficieConstruidaInt = parseInt(data.construidos, 10); \n    const parcelaInt = parseInt(data.parcela, 10); \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          superficieElementosConstructivos: superficieConstruidaInt, \n          superficieAsociadaInmueble: parcelaInt, \n        }, \n        { \n          $expr: { \n            $and: [ \n              { \n                $gte: [ \n                  { $toInt: \"$anoAntiguedadBienInmueble\" }, \n                  añoConstruccion - añoConstruccionError, \n                ], \n              },"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-130",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 130,
    "content": "{ \n                $lte: [ \n                  { $toInt: \"$anoAntiguedadBienInmueble\" }, \n                  añoConstruccion + añoConstruccionError, \n                ], \n              }, \n            ], \n          }, \n        }, \n      ], \n    }; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n97 \n\n \n  // 9. Municipio + Año error + Superficie Útil + Parcela \n  if ( \n    !encontrado && \n    localidad && \n    añoConstruccion && \n    añoConstruccionError > 0 && \n    superficieUtil && \n    parcela \n  ) { \n    const superficieUtilInt = parseInt(data.utiles, 10); \n    const parcelaInt = parseInt(data.parcela, 10); \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          superficieElementosConstructivos: superficieUtilInt, \n          superficieAsociadaInmueble: parcelaInt, \n        }, \n        { \n          $expr: { \n            $and: [ \n              { \n                $gte: [ \n                  { $toInt: \"$anoAntiguedadBienInmueble\" }, \n                  añoConstruccion - añoConstruccionError,"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-131",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 131,
    "content": "], \n              }, \n              { \n                $lte: [ \n                  { $toInt: \"$anoAntiguedadBienInmueble\" }, \n                  añoConstruccion + añoConstruccionError, \n                ], \n              }, \n            ], \n          }, \n        }, \n      ], \n    }; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 10. Municipio + Año error + Superficie Construida \n  if ( \n98 \n\n    !encontrado && \n    localidad && \n    añoConstruccion && \n    añoConstruccionError > 0 && \n    superficieConstruida \n  ) { \n    const superficieConstruidaInt = parseInt(data.construidos, 10); \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          superficieElementosConstructivos: superficieConstruidaInt, \n        }, \n        { \n          $expr: { \n            $and: [ \n              { \n                $gte: [ \n                  { $toInt: \"$anoAntiguedadBienInmueble\" }, \n                  añoConstruccion - añoConstruccionError, \n                ], \n              }, \n              { \n                $"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-132",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 132,
    "content": "lte: [ \n                  { $toInt: \"$anoAntiguedadBienInmueble\" }, \n                  añoConstruccion + añoConstruccionError, \n                ], \n              }, \n            ], \n          }, \n        }, \n      ], \n    }; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 11. Municipio + Año error + Superficie Útil \n  if ( \n    !encontrado && \n    localidad && \n    añoConstruccion && \n    añoConstruccionError > 0 && \n    superficieUtil \n  ) { \n99 \n\n    const superficieUtilInt = parseInt(data.utiles, 10); \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          superficieElementosConstructivos: superficieUtilInt, \n        }, \n        { \n          $expr: { \n            $and: [ \n              { \n                $gte: [ \n                  { $toInt: \"$anoAntiguedadBienInmueble\" }, \n                  añoConstruccion - añoConstruccionError, \n                ], \n              }, \n              { \n                $lte: [ \n                  { $toInt: \"$anoAntiguedadBienInmueble\" }, \n                  añoCo"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-133",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 133,
    "content": "nstruccion + añoConstruccionError, \n                ], \n              }, \n            ], \n          }, \n        }, \n      ], \n    }; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 12. Municipio + Año error + Parcela \n  if ( \n    !encontrado && \n    localidad && \n    añoConstruccion && \n    añoConstruccionError > 0 && \n    parcela \n  ) { \n    const parcelaInt = parseInt(data.parcela, 10); \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          superficieAsociadaInmueble: parcelaInt, \n100 \n\n        }, \n        { \n          $expr: { \n            $and: [ \n              { \n                $gte: [ \n                  { $toInt: \"$anoAntiguedadBienInmueble\" }, \n                  añoConstruccion - añoConstruccionError, \n                ], \n              }, \n              { \n                $lte: [ \n                  { $toInt: \"$anoAntiguedadBienInmueble\" }, \n                  añoConstruccion + añoConstruccionError, \n                ], \n              }, \n            ], \n          }, \n        }, \n      ],"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-134",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 134,
    "content": "}; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 13. Municipio + Superficie Construida error + Parcela \n  if ( \n    !encontrado && \n    localidad && \n    superficieConstruida && \n    areaError > 0 && \n    parcela \n  ) { \n    const superficieConstruidaInt = parseInt(data.construidos, 10); \n \n    const parcelaInt = parseInt(data.parcela, 10); \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          superficieAsociadaInmueble: parcelaInt, \n        }, \n        { \n          $expr: { \n            $and: [ \n101 \n\n              { \n                $gte: [ \n                  { $toInt: \"$superficieElementosConstructivos\" }, \n                  superficieConstruidaInt * (1 - areaError / 100), \n                ], \n              }, \n              { \n                $lte: [ \n                  { $toInt: \"$superficieElementosConstructivos\" }, \n                  superficieConstruidaInt * (1 + areaError / 100), \n                ], \n              }, \n            ], \n          }, \n        }, \n      ], \n    };"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-135",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 135,
    "content": "lista.push(JSON.stringify(condicion)); \n \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 14. Municipio + Superficie Útil error + Parcela \n  if (!encontrado && localidad && superficieUtil && areaError > 0 && \nparcela) { \n    const superficieUtilInt = parseInt(data.utiles, 10); \n \n    const parcelaInt = parseInt(data.parcela, 10); \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          superficieAsociadaInmueble: parcelaInt, \n        }, \n        { \n          $expr: { \n            $and: [ \n              { \n                $gte: [ \n                  { $toInt: \"$superficieElementosConstructivos\" }, \n                  superficieUtilInt * (1 - areaError / 100), \n                ], \n              }, \n              { \n                $lte: [ \n102 \n\n                  { $toInt: \"$superficieElementosConstructivos\" }, \n                  superficieUtilInt * (1 + areaError / 100), \n                ], \n              }, \n            ], \n          }, \n        }, \n      ], \n    }; \n    lista.push(JSON.stringify(condicion)); \n \n    possibleMatches = await"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-136",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 136,
    "content": "CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 15. Municipio + Año  + Superficie Construida error + Parcela \n  if ( \n    !encontrado && \n    areaError > 0 && \n    localidad && \n    añoConstruccion && \n    superficieConstruida && \n    parcela \n  ) { \n    const superficieConstruidaInt = parseInt(data.construidos, 10); \n    const parcelaInt = parseInt(data.parcela, 10); \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          anoAntiguedadBienInmueble: añoConstruccion, \n          superficieAsociadaInmueble: parcelaInt, \n        }, \n        { \n          $expr: { \n            $and: [ \n              { \n                $gte: [ \n                  { $toInt: \"$superficieElementosConstructivos\" }, \n                  superficieConstruidaInt * (1 - areaError / 100), \n                ], \n              }, \n              { \n                $lte: [ \n                  { $toInt: \"$superficieElementosConstructivos\" }, \n                  superficieConstruidaInt * (1 + areaError / 100), \n103 \n\n                ], \n              }, \n            ], \n          }, \n        }, \n      ], \n    }"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-137",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 137,
    "content": "; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 16. Municipio + Año + Superficie Útil error + Parcela \n  if ( \n    !encontrado && \n    areaError > 0 && \n    localidad && \n    añoConstruccion && \n    superficieUtil && \n    parcela \n  ) { \n    const superficieUtilInt = parseInt(data.utiles, 10); \n    const parcelaInt = parseInt(data.parcela, 10); \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          anoAntiguedadBienInmueble: añoConstruccion, \n          superficieAsociadaInmueble: parcelaInt, \n        }, \n        { \n          $expr: { \n            $and: [ \n              { \n                $gte: [ \n                  { $toInt: \"$superficieElementosConstructivos\" }, \n                  superficieUtilInt * (1 - areaError / 100), \n                ], \n              }, \n              { \n                $lte: [ \n                  { $toInt: \"$superficieElementosConstructivos\" }, \n                  superficieUtilInt * (1 + areaError / 100), \n                ], \n              }, \n            ], \n104"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-138",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 138,
    "content": "}, \n        }, \n      ], \n    }; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 17. Municipio + Año + Superficie Construida error \n  if ( \n    !encontrado && \n    areaError > 0 && \n    localidad && \n    añoConstruccion && \n    superficieConstruida \n  ) { \n    const superficieConstruidaInt = parseInt(data.construidos, 10); \n \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          anoAntiguedadBienInmueble: añoConstruccion, \n        }, \n        { \n          $expr: { \n            $and: [ \n              { \n                $gte: [ \n                  { $toInt: \"$superficieElementosConstructivos\" }, \n                  superficieConstruidaInt * (1 - areaError / 100), \n                ], \n              }, \n              { \n                $lte: [ \n                  { $toInt: \"$superficieElementosConstructivos\" }, \n                  superficieConstruidaInt * (1 + areaError / 100), \n                ], \n              }, \n            ], \n          }, \n        }, \n      ], \n    }; \n    lista.push(JSON"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-139",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 139,
    "content": ".stringify(condicion)); \n105 \n\n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 18. Municipio + Año + Superficie Útil error \n  if ( \n    !encontrado && \n    areaError > 0 && \n    localidad && \n    añoConstruccion && \n    superficieUtil \n  ) { \n    const superficieUtilInt = parseInt(data.utiles, 10); \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          anoAntiguedadBienInmueble: añoConstruccion, \n        }, \n        { \n          $expr: { \n            $and: [ \n              { \n                $gte: [ \n                  { $toInt: \"$superficieElementosConstructivos\" }, \n                  superficieUtilInt * (1 - areaError / 100), \n                ], \n              }, \n              { \n                $lte: [ \n                  { $toInt: \"$superficieElementosConstructivos\" }, \n                  superficieUtilInt * (1 + areaError / 100), \n                ], \n              }, \n            ], \n          }, \n        }, \n      ], \n    }; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion);"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-140",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 140,
    "content": "if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n106 \n\n  // 19. Municipio + Año + Parcela error \n  if ( \n    !encontrado && \n    localidad && \n    añoConstruccion && \n    parcelaError > 0 && \n    parcela \n  ) { \n    const parcelaInt = parseInt(data.parcela, 10); \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          anoAntiguedadBienInmueble: añoConstruccion, \n        }, \n        { \n          $expr: { \n            $and: [ \n              { \n                $gte: [ \n                  { $toInt: \"$superficieAsociadaInmueble\" }, \n                  parcelaInt * (1 - parcelaError / 100), \n                ], \n              }, \n              { \n                $lte: [ \n                  { $toInt: \"$anoAntiguedadBienInmueble\" }, \n                  añoConstruccion * (1 + parcelaError / 100), \n                ], \n              }, \n            ], \n          }, \n        }, \n      ], \n    }; \n    lista.push(JSON.stringify(condicion)); \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 20. Municipio + Superficie Construida  + Pa"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-141",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 141,
    "content": "rcela error \n  if ( \n    !encontrado && \n    localidad && \n    superficieConstruida && \n    parcelaError > 0 && \n107 \n\n    parcela \n  ) { \n    const superficieConstruidaInt = parseInt(data.construidos, 10); \n \n    const parcelaInt = parseInt(data.parcela, 10); \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          superficieElementosConstructivos: superficieConstruidaInt, \n        }, \n        { \n          $expr: { \n            $and: [ \n              { \n                $gte: [ \n                  { $toInt: \"$superficieAsociadaInmueble\" }, \n                  parcelaInt * (1 - parcelaError / 100), \n                ], \n              }, \n              { \n                $lte: [ \n                  { $toInt: \"$superficieAsociadaInmueble\" }, \n                  parcelaInt * (1 + parcelaError / 100), \n                ], \n              }, \n            ], \n          }, \n        }, \n      ], \n    }; \n    lista.push(JSON.stringify(condicion)); \n \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n \n  // 21. Municipio + Superficie Útil  + Parcela error \n  if ("
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-142",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 142,
    "content": "!encontrado && \n    localidad && \n    superficieUtil && \n    parcelaError > 0 && \n    parcela \n  ) { \n    const superficieUtilInt = parseInt(data.utiles, 10); \n108 \n\n \n    const parcelaInt = parseInt(data.parcela, 10); \n    const condicion = { \n      $and: [ \n        { \n          nombreMunicipio: localidad, \n          superficieElementosConstructivos: superficieUtilInt, \n        }, \n        { \n          $expr: { \n            $and: [ \n              { \n                $gte: [ \n                  { $toInt: \"$superficieAsociadaInmueble\" }, \n                  parcelaInt * (1 - parcelaError / 100), \n                ], \n              }, \n              { \n                $lte: [ \n                  { $toInt: \"$superficieAsociadaInmueble\" }, \n                  parcelaInt * (1 + parcelaError / 100), \n                ], \n              }, \n            ], \n          }, \n        }, \n      ], \n    }; \n    lista.push(JSON.stringify(condicion)); \n \n    possibleMatches = await CadastralProperty.find(condicion); \n    if (possibleMatches.length > 0) { \n      encontrado = true; \n    } \n  } \n  if (possibleMatches.length === 0) { \n    return { references: [], addresses: [] }; // Return an empty array \nif"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-143",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 143,
    "content": "no matches are found \n  } \n \n  let filteredMatches = possibleMatches; \n \n  // Map to reference catastral and addresses \n  const references = filteredMatches.map( \n    (property) => property.referenciaCatastral \n  ); \n  const addresses = filteredMatches.map((property) => { \n    const parts = [ \n109 \n\nJavaScript\n      property.tipoViaSiglaPublica, \n      property.nombreViaPublica, \n      property.primerNumeroPolicia, \n      property.primeraLetra || \"\", \n      property.segundoNumeroPolicia || \"\", \n      property.segundaLetra || \"\", \n      property.bloque || \"\", \n      property.escalera || \"\", \n      property.planta || \"\", \n      property.puerta || \"\", \n      property.nombreMunicipio, \n      property.nombreProvincia, \n      property.codigoPostal, \n    ] \n      .filter((part) => part !== \"\") \n      .join(\", \"); \n \n    return parts; \n  }); \n \n  return { references, addresses}; \n} \nFigure 2 Appendix:  Code to link cadastre with properties. Source: Own elaboration. \n \n \nconst numCPUs = os.cpus().length; \n \nconst poolSize = Math.max(1, Math.floor(numCPUs)); \n \nconst pool = new WorkerPool( \n  path.resolve(__dirname, \"similarityWorker.js\"), \n  poolSize \n); \nclass WorkerPool extends EventEmit"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-144",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 144,
    "content": "ter { \n  constructor(workerPath, poolSize) { \n    super(); \n    this.workerPath = workerPath; \n    this.poolSize = poolSize; \n    this.workers = []; \n    this.idleWorkers = []; \n    this.taskQueue = []; \n \n    this.init(); \n110 \n\n  } \n \n  init() { \n    for (let i = 0; i < this.poolSize; i++) { \n      this.createWorker(); \n    } \n  } \n \n  createWorker() { \n    const worker = new Worker(this.workerPath); \n \n    worker.on(\"message\", (msg) => { \n      const { resolve, reject } = worker.currentTask; \n      if (msg.error) { \n        reject(new Error(msg.error)); \n      } else { \n        resolve(msg.result); \n      } \n      worker.currentTask = null; \n      this.idleWorkers.push(worker); \n      this.runNext(); \n    }); \n \n    worker.on(\"error\", (err) => { \n      if (worker.currentTask) { \n        const { reject } = worker.currentTask; \n        reject(err); \n      } \n      this.workers = this.workers.filter((w) => w !== worker); \n      this.createWorker(); \n    }); \n \n    worker.on(\"exit\", (code) => { \n      if (code !== 0) { \n        console.error(`Worker terminado con código de salida ${code}`); \n      } \n      if (worker.currentTask) { \n        const { reject } = worker.currentTask;"
  },
  {
    "id": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt-145",
    "filename": "1757176478735-Memoria-TFG-Jos_MiguelSantos.pdf.txt",
    "chunkIndex": 145,
    "content": "reject(new Error(`Worker terminó con código de salida \n${code}`\n)); \n      } \n      this.workers = this.workers.filter((w) => w !== worker); \n      this.createWorker(); \n    }); \n \n    this.workers.push(worker); \n    this.idleWorkers.push(worker); \n  } \n111 \n\n \n  runTask(task) { \n    return new Promise((resolve, reject) => { \n      const worker = this.idleWorkers.shift(); \n      if (worker) { \n        worker.currentTask = { resolve, reject }; \n        worker.postMessage(task); \n      } else { \n        this.taskQueue.push({ task, resolve, reject }); \n      } \n    }); \n  } \n \n  runNext() { \n    if (this.taskQueue.length === 0) return; \n    const worker = this.idleWorkers.shift(); \n    if (worker) { \n      const { task, resolve, reject } = this.taskQueue.shift(); \n      worker.currentTask = { resolve, reject }; \n      worker.postMessage(task); \n    } \n  } \n \n  async close() { \n    for (const worker of this.workers) { \n      await worker.terminate(); \n    } \n    this.workers = []; \n    this.idleWorkers = []; \n    this.taskQueue = []; \n  } \n} \nFigure 3 Appendix:  Code to create a WorkerPool. Source: Own elaboration. \n112"
  }
]